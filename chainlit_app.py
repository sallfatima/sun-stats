import chainlit as cl
import sys
import os

# Ajouter le rÃ©pertoire src au path Python
sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))

# Imports dynamiques pour Ã©viter les erreurs d'import
def safe_import_rag_graph():
    """Import sÃ©curisÃ© de RAGGraph"""
    try:
        from simple_rag.graph import graph as simple_rag_graph
        return simple_rag_graph, "langgraph"
    except ImportError:
        try:
            # Fallback vers une classe RAGGraph si elle existe
            from simple_rag.graph import RAGGraph
            return RAGGraph(), "class"
        except ImportError as e:
            print(f"âŒ Erreur d'import: {e}")
            return None, None

def safe_import_retrieval_graph():
    """Import sÃ©curisÃ© du retrieval graph"""
    try:
        from retrieval_graph.graph import graph as retrieval_graph
        return retrieval_graph, "langgraph"
    except ImportError as e:
        print(f"âŒ Retrieval graph non disponible: {e}")
        return None, None

def safe_import_self_rag():
    """Import sÃ©curisÃ© du self RAG graph"""
    try:
        from self_rag.graph import graph as self_rag_graph
        return self_rag_graph, "langgraph"
    except ImportError as e:
        print(f"âŒ Self RAG non disponible: {e}")
        return None, None

# Configuration des graphiques disponibles
AVAILABLE_GRAPHS = {}

# Initialisation des graphiques
simple_rag, simple_type = safe_import_rag_graph()
if simple_rag:
    AVAILABLE_GRAPHS["simple_rag"] = {
        "name": "Simple RAG",
        "description": "RAG basique avec rÃ©cupÃ©ration et gÃ©nÃ©ration",
        "instance": simple_rag,
        "type": simple_type
    }

retrieval_graph, retrieval_type = safe_import_retrieval_graph()
if retrieval_graph:
    AVAILABLE_GRAPHS["retrieval_graph"] = {
        "name": "Retrieval Graph", 
        "description": "RAG amÃ©liorÃ© avec meilleure rÃ©cupÃ©ration",
        "instance": retrieval_graph,
        "type": retrieval_type
    }

self_rag, self_type = safe_import_self_rag()
if self_rag:
    AVAILABLE_GRAPHS["self_rag"] = {
        "name": "Self RAG",
        "description": "RAG avec auto-Ã©valuation et correction",
        "instance": self_rag,
        "type": self_type
    }

print(f"ğŸ“Š Graphiques disponibles: {list(AVAILABLE_GRAPHS.keys())}")

async def call_graph(graph_instance, user_input: str, chat_history: list, graph_type: str, graph_config: dict):
    """Appelle le graphique appropriÃ© selon son type"""
    
    if graph_config["type"] == "class":
        # Pour RAGGraph avec mÃ©thode ask
        return graph_instance.ask(user_input, chat_history)
    
    elif graph_config["type"] == "langgraph":
        # Pour les graphiques LangGraph
        from langchain_core.messages import HumanMessage, AIMessage
        
        # Convertir l'historique en messages
        messages = []
        for user_msg, bot_msg in chat_history:
            messages.append(HumanMessage(content=user_msg))
            messages.append(AIMessage(content=bot_msg))
        
        # Ajouter le message actuel
        messages.append(HumanMessage(content=user_input))
        
        # Appeler le graphique avec configuration par dÃ©faut
        config = {"configurable": {"model": "openai/gpt-4o"}}
        
        try:
            result = await graph_instance.ainvoke({"messages": messages}, config=config)
        except Exception as e:
            # Fallback sans config si erreur
            try:
                result = await graph_instance.ainvoke({"messages": messages})
            except Exception as e2:
                return f"Erreur lors de l'appel au graphique: {e2}", []
        
        # Extraire la rÃ©ponse et les documents
        if "messages" in result and result["messages"]:
            answer = result["messages"][-1].content
        else:
            answer = "Pas de rÃ©ponse gÃ©nÃ©rÃ©e"
            
        sources = result.get("documents", [])
        
        return answer, sources
    
    else:
        return "Type de graphique non supportÃ©", []

@cl.on_chat_start
async def on_chat_start():
    """Initialisation du chat"""
    
    if not AVAILABLE_GRAPHS:
        await cl.Message(
            content="âŒ **Aucun graphique disponible**\n\nVÃ©rifiez que les modules sont correctement installÃ©s."
        ).send()
        return
    
    # Interface de sÃ©lection du graphique
    if len(AVAILABLE_GRAPHS) > 1:
        actions = [
            cl.Action(
                name=graph_key,
                value=graph_key,
                label=f"{graph_info['name']}: {graph_info['description']}",
                payload={"graph_type": graph_key}
            )
            for graph_key, graph_info in AVAILABLE_GRAPHS.items()
        ]
        
        await cl.Message(
            content="ğŸ¤– **Bienvenue dans le Chatbot RGPH â€“ ANSD**\n\nChoisissez le type de RAG que vous souhaitez utiliser:",
            actions=actions
        ).send()
        
        cl.user_session.set("selected_graph", None)
    else:
        # Un seul graphique disponible, le sÃ©lectionner automatiquement
        graph_key = list(AVAILABLE_GRAPHS.keys())[0]
        graph_info = AVAILABLE_GRAPHS[graph_key]
        
        cl.user_session.set("selected_graph", graph_key)
        
        await cl.Message(
            content="ğŸ‡¸ğŸ‡³ **Bienvenue dans TERANGA IA - ANSD**\n\n"
                   f"Assistant Intelligent pour les Statistiques du SÃ©nÃ©gal\n\n"
                   f"âœ… **{graph_info['name']}** activÃ©\n\n"
                   f"ğŸ“ *{graph_info['description']}*\n\n"
                   f"**Exemples de questions :**\n"
                   f"â€¢ Quelle est la population du SÃ©nÃ©gal selon le dernier RGPH ?\n"
                   f"â€¢ Quel est le taux de pauvretÃ© au SÃ©nÃ©gal ?\n"
                   f"â€¢ Comment Ã©volue le taux d'alphabÃ©tisation ?\n\n"
                   f"Posez vos questions sur les statistiques et enquÃªtes nationales !"
        ).send()
    
    # Initialiser les variables de session
    cl.user_session.set("chat_history", [])

# Callbacks pour la sÃ©lection des graphiques
@cl.action_callback("simple_rag")
async def on_simple_rag_selected(action):
    await select_graph("simple_rag")

@cl.action_callback("retrieval_graph") 
async def on_retrieval_graph_selected(action):
    await select_graph("retrieval_graph")

@cl.action_callback("self_rag")
async def on_self_rag_selected(action):
    await select_graph("self_rag")

async def select_graph(graph_type: str):
    """SÃ©lectionne le graphique choisi"""
    if graph_type not in AVAILABLE_GRAPHS:
        await cl.Message(
            content=f"âŒ Graphique {graph_type} non disponible"
        ).send()
        return
    
    cl.user_session.set("selected_graph", graph_type)
    graph_info = AVAILABLE_GRAPHS[graph_type]
    
    await cl.Message(
        content=f"âœ… **{graph_info['name']}** sÃ©lectionnÃ© !\n\n"
               f"ğŸ“ *{graph_info['description']}*\n\n"
               f"Vous pouvez maintenant poser vos questions sur les donnÃ©es RGPH."
    ).send()

@cl.on_message
async def main(message):
    """Traitement principal des messages"""
    
    # Gestion des commandes
    content = message.content.lower().strip()
    
    if content.startswith("/switch"):
        parts = content.split()
        if len(parts) == 2 and parts[1] in AVAILABLE_GRAPHS:
            await select_graph(parts[1])
        else:
            available = ", ".join(AVAILABLE_GRAPHS.keys())
            await cl.Message(
                content=f"Usage: /switch [graph_type]\nGraphiques disponibles: {available}"
            ).send()
        return
    
    if content == "/help":
        help_text = "**ğŸ†˜ Commandes disponibles:**\n\n"
        help_text += "â€¢ `/switch [graph_type]` - Changer de graphique\n"
        help_text += "â€¢ `/help` - Afficher cette aide\n\n"
        help_text += "**ğŸ“Š EnquÃªtes et donnÃ©es disponibles :**\n"
        help_text += "â€¢ **RGPH** - Recensement GÃ©nÃ©ral Population & Habitat\n"
        help_text += "â€¢ **EDS** - EnquÃªte DÃ©mographique et de SantÃ©\n"
        help_text += "â€¢ **ESPS/EHCVM** - EnquÃªtes sur la PauvretÃ©\n"
        help_text += "â€¢ **ENES** - EnquÃªte Nationale sur l'Emploi\n"
        help_text += "â€¢ **Comptes Nationaux** - DonnÃ©es Ã©conomiques\n\n"
        for key, info in AVAILABLE_GRAPHS.items():
            help_text += f"â€¢ `{key}` - {info['name']}: {info['description']}\n"
        
        await cl.Message(content=help_text).send()
        return
    
    # VÃ©rifier qu'un graphique a Ã©tÃ© sÃ©lectionnÃ©
    selected_graph = cl.user_session.get("selected_graph")
    
    if not selected_graph:
        await cl.Message(
            content="âš ï¸ Veuillez d'abord sÃ©lectionner un type de RAG."
        ).send()
        return
    
    if selected_graph not in AVAILABLE_GRAPHS:
        await cl.Message(
            content=f"âŒ Graphique {selected_graph} non disponible"
        ).send()
        return
    
    try:
        # 1. RÃ©cupÃ©rer l'historique
        chat_history = cl.user_session.get("chat_history", [])
        
        # 2. Extraire le texte du message
        user_input = message.content
        
        # 3. Limiter l'historique envoyÃ©
        short_history = chat_history[-5:]
        
        # 4. Afficher un indicateur de traitement
        graph_info = AVAILABLE_GRAPHS[selected_graph]
        processing_msg = await cl.Message(
            content=f"ğŸ” Traitement avec **{graph_info['name']}**..."
        ).send()
        
        # 5. Appeler le graphique appropriÃ©
        answer, sources = await call_graph(
            graph_info["instance"], 
            user_input, 
            short_history, 
            selected_graph,
            graph_info
        )
        
        # 6. Supprimer le message de traitement
        await processing_msg.remove()
        
        # 7. Mettre Ã  jour l'historique
        chat_history.append((user_input, answer))
        cl.user_session.set("chat_history", chat_history)
        
        # 8. Envoyer la rÃ©ponse
        await cl.Message(
            content=f"**{graph_info['name']}** rÃ©pond:\n\n{answer}"
        ).send()
        
        # # 9. Envoyer les sources si disponibles
        # if sources and len(sources) > 0:
        #     sources_md = "\n".join(
        #         f"- `{doc.metadata.get('source_pdf', doc.metadata.get('source', 'inconnu'))}` (chunk `{doc.metadata.get('chunk', '?')}`)"
        #         for doc in sources
        #     )
        #     await cl.Message(
        #         content=f"**ğŸ“š Sources utilisÃ©es :**\n{sources_md}"
        #     ).send()
        
    except Exception as e:
        await cl.Message(
            content=f"âŒ Erreur lors du traitement: {str(e)}"
        ).send()
        print(f"Erreur dÃ©taillÃ©e: {e}")
        import traceback
        traceback.print_exc()