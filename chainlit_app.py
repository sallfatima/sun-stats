import chainlit as cl
import sys
import os

# Ajouter le r√©pertoire src au path Python
sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))

# Imports dynamiques pour √©viter les erreurs d'import
def safe_import_rag_graph():
    """Import s√©curis√© de RAGGraph"""
    try:
        from simple_rag.graph import graph as simple_rag_graph
        return simple_rag_graph, "langgraph"
    except ImportError:
        try:
            # Fallback vers une classe RAGGraph si elle existe
            from simple_rag.graph import RAGGraph
            return RAGGraph(), "class"
        except ImportError as e:
            print(f"‚ùå Erreur d'import: {e}")
            return None, None

def safe_import_retrieval_graph():
    """Import s√©curis√© du retrieval graph"""
    try:
        from retrieval_graph.graph import graph as retrieval_graph
        return retrieval_graph, "langgraph"
    except ImportError as e:
        print(f"‚ùå Retrieval graph non disponible: {e}")
        return None, None

def safe_import_self_rag():
    """Import s√©curis√© du self RAG graph"""
    try:
        from self_rag.graph import graph as self_rag_graph
        return self_rag_graph, "langgraph"
    except ImportError as e:
        print(f"‚ùå Self RAG non disponible: {e}")
        return None, None

# Configuration des graphiques disponibles
AVAILABLE_GRAPHS = {}

# Initialisation des graphiques
simple_rag, simple_type = safe_import_rag_graph()
if simple_rag:
    AVAILABLE_GRAPHS["simple_rag"] = {
        "name": "Simple RAG",
        "description": "RAG basique avec r√©cup√©ration et g√©n√©ration",
        "instance": simple_rag,
        "type": simple_type
    }

retrieval_graph, retrieval_type = safe_import_retrieval_graph()
if retrieval_graph:
    AVAILABLE_GRAPHS["retrieval_graph"] = {
        "name": "Retrieval Graph", 
        "description": "RAG am√©lior√© avec meilleure r√©cup√©ration",
        "instance": retrieval_graph,
        "type": retrieval_type
    }

self_rag, self_type = safe_import_self_rag()
if self_rag:
    AVAILABLE_GRAPHS["self_rag"] = {
        "name": "Self RAG",
        "description": "RAG avec auto-√©valuation et correction",
        "instance": self_rag,
        "type": self_type
    }

print(f"üìä Graphiques disponibles: {list(AVAILABLE_GRAPHS.keys())}")

async def call_graph(graph_instance, user_input: str, chat_history: list, graph_type: str, graph_config: dict):
    """Appelle le graphique appropri√© selon son type"""
    
    if graph_config["type"] == "class":
        # Pour RAGGraph avec m√©thode ask
        return graph_instance.ask(user_input, chat_history)
    
    elif graph_config["type"] == "langgraph":
        # Pour les graphiques LangGraph
        from langchain_core.messages import HumanMessage, AIMessage
        
        # Convertir l'historique en messages
        messages = []
        for user_msg, bot_msg in chat_history:
            messages.append(HumanMessage(content=user_msg))
            messages.append(AIMessage(content=bot_msg))
        
        # Ajouter le message actuel
        messages.append(HumanMessage(content=user_input))
        
        # Appeler le graphique avec configuration par d√©faut
        config = {"configurable": {"model": "openai/gpt-4o"}}
        
        try:
            result = await graph_instance.ainvoke({"messages": messages}, config=config)
        except Exception as e:
            # Fallback sans config si erreur
            try:
                result = await graph_instance.ainvoke({"messages": messages})
            except Exception as e2:
                return f"Erreur lors de l'appel au graphique: {e2}", []
        
        # Extraire la r√©ponse et les documents
        if "messages" in result and result["messages"]:
            answer = result["messages"][-1].content
        else:
            answer = "Pas de r√©ponse g√©n√©r√©e"
            
        sources = result.get("documents", [])
        
        return answer, sources
    
    else:
        return "Type de graphique non support√©", []

@cl.on_chat_start
async def on_chat_start():
    """Initialisation du chat"""
    
    if not AVAILABLE_GRAPHS:
        await cl.Message(
            content="‚ùå **Aucun graphique disponible**\n\nV√©rifiez que les modules sont correctement install√©s."
        ).send()
        return
    
    # Interface de s√©lection du graphique
    if len(AVAILABLE_GRAPHS) > 1:
        actions = [
            cl.Action(
                name=graph_key,
                value=graph_key,
                label=f"{graph_info['name']}: {graph_info['description']}",
                payload={"graph_type": graph_key}
            )
            for graph_key, graph_info in AVAILABLE_GRAPHS.items()
        ]
        
        await cl.Message(
            content="ü§ñ **Bienvenue dans le Chatbot RGPH ‚Äì ANSD**\n\nChoisissez le type de RAG que vous souhaitez utiliser:",
            actions=actions
        ).send()
        
        cl.user_session.set("selected_graph", None)
    else:
        # Un seul graphique disponible, le s√©lectionner automatiquement
        graph_key = list(AVAILABLE_GRAPHS.keys())[0]
        graph_info = AVAILABLE_GRAPHS[graph_key]
        
        cl.user_session.set("selected_graph", graph_key)
        
        await cl.Message(
            content="üá∏üá≥ **Bienvenue dans TERANGA IA - ANSD**\n\n"
                   f"Assistant Intelligent pour les Statistiques du S√©n√©gal\n\n"
                   f"‚úÖ **{graph_info['name']}** activ√©\n\n"
                   f"üìù *{graph_info['description']}*\n\n"
                   f"**Exemples de questions :**\n"
                   f"‚Ä¢ Quelle est la population du S√©n√©gal selon le dernier RGPH ?\n"
                   f"‚Ä¢ Quel est le taux de pauvret√© au S√©n√©gal ?\n"
                   f"‚Ä¢ Comment √©volue le taux d'alphab√©tisation ?\n\n"
                   f"Posez vos questions sur les statistiques et enqu√™tes nationales !"
        ).send()
    
    # Initialiser les variables de session
    cl.user_session.set("chat_history", [])

# Callbacks pour la s√©lection des graphiques
@cl.action_callback("simple_rag")
async def on_simple_rag_selected(action):
    await select_graph("simple_rag")

@cl.action_callback("retrieval_graph") 
async def on_retrieval_graph_selected(action):
    await select_graph("retrieval_graph")

@cl.action_callback("self_rag")
async def on_self_rag_selected(action):
    await select_graph("self_rag")

async def select_graph(graph_type: str):
    """S√©lectionne le graphique choisi"""
    if graph_type not in AVAILABLE_GRAPHS:
        await cl.Message(
            content=f"‚ùå Graphique {graph_type} non disponible"
        ).send()
        return
    
    cl.user_session.set("selected_graph", graph_type)
    graph_info = AVAILABLE_GRAPHS[graph_type]
    
    await cl.Message(
        content=f"‚úÖ **{graph_info['name']}** s√©lectionn√© !\n\n"
               f"üìù *{graph_info['description']}*\n\n"
               f"Vous pouvez maintenant poser vos questions sur les donn√©es RGPH."
    ).send()

@cl.on_message
async def main(message):
    """Traitement principal des messages"""
    
    # Gestion des commandes
    content = message.content.lower().strip()
    
    if content.startswith("/switch"):
        parts = content.split()
        if len(parts) == 2 and parts[1] in AVAILABLE_GRAPHS:
            await select_graph(parts[1])
        else:
            available = ", ".join(AVAILABLE_GRAPHS.keys())
            await cl.Message(
                content=f"Usage: /switch [graph_type]\nGraphiques disponibles: {available}"
            ).send()
        return
    
    if content == "/help":
        help_text = "**üÜò Commandes disponibles:**\n\n"
        help_text += "‚Ä¢ `/switch [graph_type]` - Changer de graphique\n"
        help_text += "‚Ä¢ `/help` - Afficher cette aide\n\n"
        help_text += "**üìä Enqu√™tes et donn√©es disponibles :**\n"
        help_text += "‚Ä¢ **RGPH** - Recensement G√©n√©ral Population & Habitat\n"
        help_text += "‚Ä¢ **EDS** - Enqu√™te D√©mographique et de Sant√©\n"
        help_text += "‚Ä¢ **ESPS/EHCVM** - Enqu√™tes sur la Pauvret√©\n"
        help_text += "‚Ä¢ **ENES** - Enqu√™te Nationale sur l'Emploi\n"
        help_text += "‚Ä¢ **Comptes Nationaux** - Donn√©es √©conomiques\n\n"
        for key, info in AVAILABLE_GRAPHS.items():
            help_text += f"‚Ä¢ `{key}` - {info['name']}: {info['description']}\n"
        
        await cl.Message(content=help_text).send()
        return
    
    # V√©rifier qu'un graphique a √©t√© s√©lectionn√©
    selected_graph = cl.user_session.get("selected_graph")
    
    if not selected_graph:
        await cl.Message(
            content="‚ö†Ô∏è Veuillez d'abord s√©lectionner un type de RAG."
        ).send()
        return
    
    if selected_graph not in AVAILABLE_GRAPHS:
        await cl.Message(
            content=f"‚ùå Graphique {selected_graph} non disponible"
        ).send()
        return
    
    try:
        # 1. R√©cup√©rer l'historique
        chat_history = cl.user_session.get("chat_history", [])
        
        # 2. Extraire le texte du message
        user_input = message.content
        
        # 3. Limiter l'historique envoy√©
        short_history = chat_history[-5:]
        
        # 4. Afficher un indicateur de traitement
        graph_info = AVAILABLE_GRAPHS[selected_graph]
        processing_msg = await cl.Message(
            content=f"üîç Traitement avec **{graph_info['name']}**..."
        ).send()
        
        # 5. Appeler le graphique appropri√©
        answer, sources = await call_graph(
            graph_info["instance"], 
            user_input, 
            short_history, 
            selected_graph,
            graph_info
        )
        
        # 6. Supprimer le message de traitement
        await processing_msg.remove()
        
        # 7. Mettre √† jour l'historique
        chat_history.append((user_input, answer))
        cl.user_session.set("chat_history", chat_history)
        
        # 8. Envoyer la r√©ponse
        await cl.Message(
            content=f"**{graph_info['name']}** r√©pond:\n\n{answer}"
        ).send()
        
        # # 9. Envoyer les sources si disponibles
        # if sources and len(sources) > 0:
        #     sources_md = "\n".join(
        #         f"- `{doc.metadata.get('source_pdf', doc.metadata.get('source', 'inconnu'))}` (chunk `{doc.metadata.get('chunk', '?')}`)"
        #         for doc in sources
        #     )
        #     await cl.Message(
        #         content=f"**üìö Sources utilis√©es :**\n{sources_md}"
        #     ).send()
        
    except Exception as e:
        await cl.Message(
            content=f"‚ùå Erreur lors du traitement: {str(e)}"
        ).send()
        print(f"Erreur d√©taill√©e: {e}")
        import traceback
        traceback.print_exc()