# =============================================================================
# FICHIER: src/simple_rag/graph.py
# =============================================================================

"""
Syst√®me RAG simple am√©lior√© pour l'ANSD avec support du contenu visuel.
"""

import os
import asyncio
from typing import Dict, List, Any, Tuple
import re

from langchain import hub
from langchain_core.messages import HumanMessage, AIMessage
from langchain_core.prompts import PromptTemplate
from langchain.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnableConfig
from langgraph.graph import END, START, StateGraph

from shared import retrieval
from shared.utils import load_chat_model
from simple_rag.configuration import RagConfiguration
from simple_rag.state import GraphState, InputState

# =============================================================================
# PROMPT SYSTEM AM√âLIOR√â POUR L'ANSD
# =============================================================================

IMPROVED_ANSD_SYSTEM_PROMPT = """Vous √™tes un expert statisticien de l'ANSD (Agence Nationale de la Statistique et de la D√©mographie du S√©n√©gal), sp√©cialis√© dans l'analyse de donn√©es d√©mographiques, √©conomiques et sociales du S√©n√©gal.

MISSION PRINCIPALE :
R√©pondre de mani√®re compl√®te et approfondie aux questions sur les statistiques du S√©n√©gal en utilisant PRIORITAIREMENT les documents fournis et en compl√©tant avec vos connaissances des publications officielles de l'ANSD.

SOURCES AUTORIS√âES :
‚úÖ Documents fournis dans le contexte (PRIORIT√â ABSOLUE)
‚úÖ Connaissances des rapports officiels ANSD publi√©s
‚úÖ Donn√©es du site officiel ANSD (www.ansd.sn)
‚úÖ Publications officielles des enqu√™tes ANSD (RGPH, EDS, ESPS, EHCVM, ENES)
‚úÖ Comptes nationaux et statistiques √©conomiques officielles du S√©n√©gal
‚úÖ Projections d√©mographiques officielles de l'ANSD

‚ùå SOURCES INTERDITES :
‚ùå Donn√©es d'autres pays pour combler les lacunes
‚ùå Estimations personnelles non bas√©es sur les sources ANSD
‚ùå Informations non officielles ou de sources tierces
‚ùå Projections personnelles non document√©es

R√àGLES DE R√âDACTION :
‚úÖ R√©ponse directe : SANS limitation de phrases - d√©veloppez autant que n√©cessaire
‚úÖ Contexte additionnel : SANS limitation - incluez toutes les informations pertinentes
‚úÖ Citez TOUJOURS vos sources pr√©cises (document + page ou publication ANSD)
‚úÖ Distinguez clairement les donn√©es des documents fournis vs connaissances ANSD
‚úÖ Donnez les chiffres EXACTS quand disponibles
‚úÖ Pr√©cisez SYST√âMATIQUEMENT les ann√©es de r√©f√©rence
‚úÖ Mentionnez les m√©thodologies d'enqu√™te

FORMAT DE R√âPONSE OBLIGATOIRE :

**R√âPONSE DIRECTE :**
[D√©veloppez la r√©ponse de mani√®re compl√®te et d√©taill√©e, sans limitation de longueur. Incluez tous les √©l√©ments pertinents pour une compr√©hension approfondie du sujet.]

**DONN√âES PR√âCISES :**
- Chiffres cl√©s : [valeurs exactes avec unit√©s]
- Ann√©es de r√©f√©rence : [p√©riodes des donn√©es]
- M√©thodologie : [type d'enqu√™te, √©chantillon, m√©thode]
- Couverture g√©ographique : [nationale, r√©gionale, urbain/rural]

**CONTEXTE ADDITIONNEL :**
[Informations compl√©mentaires, √©volutions, comparaisons, explications m√©thodologiques]

**SOURCES :**
[Liste pr√©cise des documents et pages consult√©s]

Contexte: {context}"""

# =============================================================================
# FONCTIONS UTILITAIRES POUR LE SCORING ET LE PR√âTRAITEMENT
# =============================================================================

def preprocess_query(query: str) -> str:
    """
    Pr√©traite la requ√™te utilisateur pour am√©liorer la recherche.
    
    Args:
        query: Requ√™te originale de l'utilisateur
        
    Returns:
        Requ√™te enrichie avec synonymes et termes ANSD
    """
    # Synonymes sp√©cifiques ANSD
    ansd_synonyms = {
        'population': ['habitants', 'd√©mographie', 'peuplement', 'r√©sidents'],
        'm√©nages': ['foyers', 'familles', 'unit√©s r√©sidentielles'],
        'pauvret√©': ['indigence', 'pr√©carit√©', 'conditions de vie'],
        'emploi': ['travail', 'activit√© √©conomique', 'occupation', 'profession'],
        '√©ducation': ['scolarisation', 'alphab√©tisation', 'instruction'],
        'sant√©': ['morbidit√©', 'mortalit√©', '√©tat sanitaire'],
        'urbain': ['ville', 'citadin', 'agglom√©ration'],
        'rural': ['campagne', 'agricole', 'villageois'],
        'r√©gion': ['administrative', 'territoire', 'zone g√©ographique'],
        'taux': ['pourcentage', 'proportion', 'ratio'],
        '√©volution': ['tendance', 'progression', 'changement'],
        'r√©partition': ['distribution', 'ventilation', 'structure']
    }
    
    # Enrichir la requ√™te
    enriched_terms = [query.lower()]
    
    for keyword, synonyms in ansd_synonyms.items():
        if keyword in query.lower():
            enriched_terms.extend(synonyms[:2])  # Ajouter 2 synonymes max
    
    # Ajouter des termes contextuels ANSD
    if any(term in query.lower() for term in ['population', 'habitants', 'recensement']):
        enriched_terms.append('rgph')
    
    if any(term in query.lower() for term in ['pauvret√©', 'conditions', 'vie']):
        enriched_terms.append('esps ehcvm')
    
    if any(term in query.lower() for term in ['emploi', 'ch√¥mage', 'activit√©']):
        enriched_terms.append('enes')
    
    if any(term in query.lower() for term in ['sant√©', 'd√©mographique']):
        enriched_terms.append('eds')
    
    return ' '.join(enriched_terms)


def score_documents_relevance(documents: List[Any], query: str) -> List[Tuple[float, Any]]:
    """
    Score les documents selon leur pertinence pour la requ√™te.
    
    Args:
        documents: Liste des documents √† scorer
        query: Requ√™te originale
        
    Returns:
        Liste de tuples (score, document) tri√©e par score d√©croissant
    """
    scored_documents = []
    query_lower = query.lower()
    
    # Mots-cl√©s importants pour l'ANSD
    important_keywords = [
        'population', 'm√©nages', 'pauvret√©', 'emploi', '√©ducation', 
        'sant√©', 'r√©gion', 'urbain', 'rural', 'taux', 'pourcentage',
        'rgph', 'eds', 'esps', 'ehcvm', 'enes', 'ansd'
    ]
    
    for doc in documents:
        score = 0
        content = getattr(doc, 'page_content', '').lower()
        metadata = getattr(doc, 'metadata', {})
        
        # Score bas√© sur les mots-cl√©s dans le contenu
        for keyword in important_keywords:
            if keyword in query_lower and keyword in content:
                score += 5
        
        # Score bas√© sur les m√©tadonn√©es
        if 'survey_type' in metadata:
            survey_type = metadata['survey_type'].lower()
            if survey_type in query_lower:
                score += 10
        
        # Score bas√© sur le type de document
        doc_type = metadata.get('type', '')
        if doc_type in ['visual_chart', 'visual_table']:
            score += 8  # Bonus pour le contenu visuel
        
        # Score bas√© sur la correspondance textuelle g√©n√©rale
        query_words = query_lower.split()
        for word in query_words:
            if len(word) > 3:
                score += content.count(word) * 2
        
        scored_documents.append((score, doc))
    
    # Trier par score d√©croissant
    scored_documents.sort(key=lambda x: x[0], reverse=True)
    return scored_documents


def format_docs_with_rich_metadata(docs: List[Any]) -> str:
    """
    Formate les documents avec m√©tadonn√©es enrichies pour le prompt.
    
    Args:
        docs: Documents √† formater
        
    Returns:
        Contexte format√© avec m√©tadonn√©es riches
    """
    if not docs:
        return "‚ùå Aucun document pertinent trouv√© dans la base de donn√©es ANSD."
    
    formatted_parts = []
    
    for i, doc in enumerate(docs, 1):
        # Extraction des m√©tadonn√©es
        metadata = doc.metadata if hasattr(doc, 'metadata') else {}
        
        # Informations sur la source
        source_info = []
        if 'source' in metadata:
            source_info.append(f"üìÑ Source: {metadata['source']}")
        if 'pdf_name' in metadata:
            source_info.append(f"üìã Document: {metadata['pdf_name']}")
        if 'page_num' in metadata:
            source_info.append(f"üìñ Page: {metadata['page_num']}")
        if 'page' in metadata:
            source_info.append(f"üìñ Page: {metadata['page']}")
        if 'type' in metadata:
            source_info.append(f"üîñ Type: {metadata['type']}")
        if 'caption' in metadata:
            source_info.append(f"üìä Titre: {metadata['caption']}")
        
        # En-t√™te du document
        header = f"\n{'='*50}\nüìä DOCUMENT ANSD #{i}\n"
        if source_info:
            header += "\n".join(source_info) + "\n"
        header += f"{'='*50}\n"
        
        # Contenu avec nettoyage
        content = doc.page_content.strip()
        
        # D√©tecter le type de contenu
        content_indicators = []
        if any(keyword in content.lower() for keyword in ['rgph', 'recensement']):
            content_indicators.append("üèòÔ∏è RECENSEMENT")
        if any(keyword in content.lower() for keyword in ['eds', 'd√©mographique']):
            content_indicators.append("üë• D√âMOGRAPHIE")
        if any(keyword in content.lower() for keyword in ['esps', 'pauvret√©']):
            content_indicators.append("üí∞ PAUVRET√â")
        if any(keyword in content.lower() for keyword in ['√©conomie', 'pib']):
            content_indicators.append("üìà √âCONOMIE")
        if metadata.get('type') in ['visual_chart', 'visual_table']:
            content_indicators.append("üé® VISUEL")
        
        if content_indicators:
            header += f"üè∑Ô∏è Cat√©gories: {' | '.join(content_indicators)}\n{'-'*50}\n"
        
        formatted_parts.append(f"{header}\n{content}\n")
    
    return "\n".join(formatted_parts)


def enrich_query_for_visual_content(question: str) -> str:
    """
    Enrichit la requ√™te pour am√©liorer la r√©cup√©ration de contenu visuel.
    
    Args:
        question: Question originale de l'utilisateur
        
    Returns:
        Requ√™te enrichie pour la recherche
    """
    # Mots-cl√©s qui sugg√®rent du contenu visuel
    visual_keywords = {
        'r√©partition': ['graphique', 'diagramme', 'pourcentage'],
        '√©volution': ['courbe', 'tendance', 'graphique'],
        'comparaison': ['tableau', 'donn√©es', 'statistiques'],
        'taux': ['pourcentage', 'graphique', 'donn√©es'],
        'structure': ['r√©partition', 'graphique', 'diagramme'],
        'donn√©es': ['tableau', 'statistiques', 'chiffres'],
        'statistiques': ['tableau', 'donn√©es', 'chiffres'],
        'pourcentage': ['r√©partition', 'graphique', 'diagramme']
    }
    
    # Construire la requ√™te enrichie
    query_parts = [question]
    
    question_lower = question.lower()
    
    # Ajouter des termes de recherche visuelle pertinents
    for keyword, related_terms in visual_keywords.items():
        if keyword in question_lower:
            query_parts.extend(related_terms[:2])  # Ajouter 2 termes li√©s max
    
    # Ajouter des termes g√©n√©riques pour le contenu visuel
    if any(term in question_lower for term in ['r√©partition', '√©volution', 'taux', 'pourcentage']):
        query_parts.append('visual_chart')
        query_parts.append('graphique')
    
    if any(term in question_lower for term in ['donn√©es', 'tableau', 'statistiques']):
        query_parts.append('visual_table')
        query_parts.append('tableau')
    
    return ' '.join(query_parts)


# =============================================================================
# FONCTIONS PRINCIPALES DU WORKFLOW
# =============================================================================

async def retrieve(state: GraphState, config: RunnableConfig) -> dict:
    """
    Fonction de r√©cup√©ration corrig√©e pour Pinecone avec gestion d'√©tat appropri√©e
    """
    print("üîç ---RETRIEVE AVEC SUPPORT VISUEL AM√âLIOR√â---")
    
    try:
        # CORRECTION PRINCIPALE : Acc√®s correct aux messages selon le type de GraphState
        messages = []
        
        # M√©thode 1 : Si state a un attribut messages
        if hasattr(state, 'messages'):
            messages = state.messages
        # M√©thode 2 : Si state est un dictionnaire
        elif isinstance(state, dict) and 'messages' in state:
            messages = state['messages']
        # M√©thode 3 : Si state a une m√©thode d'acc√®s sp√©cifique
        elif hasattr(state, '__getitem__'):
            try:
                messages = state['messages']
            except (KeyError, TypeError):
                messages = []
        
        if not messages:
            print("‚ö†Ô∏è Aucun message trouv√© dans l'√©tat")
            return {"documents": []}
        
        # R√©cup√©rer la derni√®re question
        last_message = messages[-1]
        if hasattr(last_message, 'content'):
            user_question = last_message.content
        else:
            user_question = str(last_message)
        
        print(f"‚ùì Question originale: {user_question}")
        
        # Enrichir la requ√™te avec support visuel
        enriched_query = enrich_query_for_visual_content(user_question)
        print(f"üîç Requ√™te enrichie: {enriched_query}")
        
        # Configuration de r√©cup√©ration
        configuration = RagConfiguration.from_runnable_config(config)
        retrieval_k = getattr(configuration, 'retrieval_k', 15)
        
        # CORRECTION : Appel s√©curis√© du retriever Pinecone
        try:
            retriever = load_pinecone_retriever(configuration)
            
            # Utiliser run_in_executor pour √©viter les probl√®mes de contexte asynchrone
            loop = asyncio.get_event_loop()
            
            def sync_retrieve():
                """Fonction synchrone pour r√©cup√©rer les documents"""
                try:
                    # Essayer diff√©rentes m√©thodes selon ce qui est disponible
                    if hasattr(retriever, 'get_relevant_documents'):
                        return retriever.get_relevant_documents(enriched_query)
                    elif hasattr(retriever, 'similarity_search'):
                        return retriever.similarity_search(enriched_query, k=retrieval_k)
                    elif hasattr(retriever, 'invoke'):
                        return retriever.invoke(enriched_query)
                    else:
                        print("‚ùå Aucune m√©thode de r√©cup√©ration trouv√©e sur le retriever")
                        return []
                except Exception as e:
                    print(f"‚ùå Erreur dans sync_retrieve: {e}")
                    return []
            
            print("üîÑ Appel du retriever Pinecone via run_in_executor...")
            documents = await loop.run_in_executor(None, sync_retrieve)
            print(f"‚úÖ R√©cup√©ration Pinecone r√©ussie: {len(documents)} documents")
        
        except Exception as e:
            print(f"‚ùå Erreur dans l'appel du retriever Pinecone: {e}")
            import traceback
            traceback.print_exc()
            
            # Fallback : retourner des documents vides plut√¥t que de planter
            print("üîÑ Utilisation de fallback...")
            documents = []
        
        print(f"üìÑ Documents r√©cup√©r√©s: {len(documents)}")
        
        # Analyse et filtrage des documents
        if documents:
            try:
                documents = analyze_and_score_documents(documents, user_question)
                print(f"üìä Apr√®s analyse: {len(documents)} documents")
            except Exception as e:
                print(f"‚ö†Ô∏è Erreur dans analyze_and_score_documents: {e}")
                # Garder les documents originaux si l'analyse √©choue
        
        return {"documents": documents}
        
    except Exception as e:
        print(f"‚ùå ERREUR GLOBALE dans retrieve: {e}")
        import traceback
        traceback.print_exc()
        return {"documents": []}


def load_pinecone_retriever(configuration):
    """
    Charge le retriever Pinecone de mani√®re s√©curis√©e
    """
    try:
        print("üîå Chargement retriever Pinecone...")
        from langchain_pinecone import PineconeVectorStore
        from langchain_openai import OpenAIEmbeddings
        
        # Configuration des embeddings
        embeddings = OpenAIEmbeddings()
        
        # Configuration Pinecone
        index_name = getattr(configuration, 'pinecone_index', os.getenv('PINECONE_INDEX', 'index-ansd'))
        print(f"üìå Index Pinecone: {index_name}")
        
        # Cr√©er le vectorstore
        vectorstore = PineconeVectorStore.from_existing_index(
            index_name=index_name,
            embedding=embeddings
        )
        
        # Cr√©er le retriever
        retriever = vectorstore.as_retriever(
            search_kwargs={
                "k": getattr(configuration, 'retrieval_k', 15),
                "score_threshold": 0.5  # Optionnel : seuil de pertinence
            }
        )
        
        print("‚úÖ Retriever Pinecone charg√© avec succ√®s")
        return retriever
        
    except Exception as e:
        print(f"‚ùå Erreur chargement retriever Pinecone: {e}")
        raise e


def analyze_and_score_documents(documents: List[Any], query: str) -> List[Any]:
    """
    Analyse et score les documents r√©cup√©r√©s, s√©pare le contenu visuel
    """
    try:
        if not documents:
            return documents
        
        # S√©parer et scorer les documents
        text_docs = []
        visual_docs = []
        
        for doc in documents:
            metadata = getattr(doc, 'metadata', {})
            doc_type = metadata.get('type', '')
            
            # Identifier les documents visuels
            if doc_type in ['visual_chart', 'visual_table']:
                visual_docs.append(doc)
            else:
                text_docs.append(doc)
        
        # Scorer et trier les documents textuels
        if text_docs:
            scored_text_docs = score_documents_relevance(text_docs, query)
            text_docs = [doc for score, doc in scored_text_docs]
        
        # Scorer et trier les documents visuels
        if visual_docs:
            scored_visual_docs = score_documents_relevance(visual_docs, query)
            visual_docs = [doc for score, doc in scored_visual_docs]
        
        # Combiner en priorisant les documents textuels puis visuels
        combined_docs = text_docs + visual_docs
        
        print(f"üìä Documents tri√©s: {len(text_docs)} textuels + {len(visual_docs)} visuels")
        return combined_docs
        
    except Exception as e:
        print(f"‚ö†Ô∏è Erreur analyse documents: {e}")
        return documents


async def generate(state: GraphState, *, config: RagConfiguration):
    """G√©n√©ration avec support d'affichage automatique du contenu visuel."""
    
    print("ü§ñ ---GENERATE AVEC SUPPORT VISUEL---")
    
    messages = state.messages
    documents = state.documents
    
    configuration = RagConfiguration.from_runnable_config(config)
    model = load_chat_model(configuration.model)
    
    # Extraire la question
    user_question = ""
    for msg in messages:
        if hasattr(msg, 'content'):
            user_question = msg.content
            break
    
    print(f"‚ùì Question: {user_question}")
    print(f"üìÑ Total documents: {len(documents)}")
    
    # S√©parer le contenu textuel et visuel
    text_docs = []
    visual_docs = []
    
    for doc in documents:
        metadata = getattr(doc, 'metadata', {})
        doc_type = metadata.get('type', '')
        
        if doc_type in ['visual_chart', 'visual_table']:
            visual_docs.append(doc)
        else:
            text_docs.append(doc)
    
    print(f"üìù Documents textuels pour g√©n√©ration: {len(text_docs)}")
    print(f"üé® Documents visuels d√©tect√©s: {len(visual_docs)}")
    
    # G√©n√©rer la r√©ponse bas√©e sur le contenu textuel et visuel combin√©
    prompt = ChatPromptTemplate.from_messages([
        ("system", IMPROVED_ANSD_SYSTEM_PROMPT),
        ("human", "{question}")
    ])
    
    # Utiliser tous les documents (textuels + visuels) pour le contexte
    context = format_docs_with_rich_metadata(documents)
    
    response = await (prompt | model).ainvoke({
        "context": context,
        "question": user_question
    })
    
    textual_response = response.content
    
    # Enrichir la r√©ponse si du contenu visuel est disponible
    if visual_docs:
        # Ajouter une mention des √©l√©ments visuels disponibles
        visual_summary = create_visual_content_summary(visual_docs)
        
        enhanced_response = f"""{textual_response}

üìä **√âl√©ments visuels disponibles :**
{visual_summary}

*Les graphiques et tableaux correspondants seront affich√©s automatiquement dans le chat.*"""
        
        final_response = enhanced_response
        
        # Marquer la r√©ponse avec des m√©tadonn√©es pour l'affichage visuel
        response_metadata = {
            'has_visual_content': True,
            'visual_count': len(visual_docs),
            'visual_types': [doc.metadata.get('type', 'unknown') for doc in visual_docs]
        }
        
    else:
        final_response = textual_response
        response_metadata = {'has_visual_content': False}
    
    # Cr√©er la r√©ponse finale
    enhanced_response = AIMessage(
        content=final_response,
        response_metadata=response_metadata
    )
    
    print(f"‚úÖ R√©ponse g√©n√©r√©e avec {len(visual_docs)} √©l√©ments visuels")
    
    return {"messages": [enhanced_response], "documents": documents}


def create_visual_content_summary(visual_docs: List[Any]) -> str:
    """
    Cr√©e un r√©sum√© textuel des √©l√©ments visuels disponibles.
    
    Args:
        visual_docs: Documents visuels
        
    Returns:
        R√©sum√© format√© des √©l√©ments visuels
    """
    summary_parts = []
    
    charts_count = 0
    tables_count = 0
    
    for i, doc in enumerate(visual_docs, 1):
        metadata = getattr(doc, 'metadata', {})
        doc_type = metadata.get('type', 'unknown')
        caption = metadata.get('caption', f'√âl√©ment {i}')
        pdf_name = metadata.get('pdf_name', 'Document ANSD')
        page = metadata.get('page', '')
        
        if doc_type == 'visual_chart':
            charts_count += 1
            icon = "üìä"
        elif doc_type == 'visual_table':
            tables_count += 1
            icon = "üìã"
        else:
            icon = "üìÑ"
        
        source_info = f"{pdf_name}"
        if page:
            source_info += f" (page {page})"
        
        summary_parts.append(f"{icon} **{caption}** - *{source_info}*")
    
    # Ajouter un r√©sum√© en en-t√™te
    summary_header = []
    if charts_count > 0:
        summary_header.append(f"{charts_count} graphique(s)")
    if tables_count > 0:
        summary_header.append(f"{tables_count} tableau(x)")
    
    if summary_header:
        header = " et ".join(summary_header)
        summary_parts.insert(0, f"*{header} trouv√©(s) :*\n")
    
    return "\n".join(summary_parts)


# =============================================================================
# FONCTIONS DE DEBUG ET DIAGNOSTIC
# =============================================================================

def extract_priority_sources(documents: List[Any]) -> List[str]:
    """Extrait les sources prioritaires des documents."""
    
    priority_sources = []
    
    for doc in documents:
        metadata = getattr(doc, 'metadata', {})
        
        # Construire la source √† partir des m√©tadonn√©es
        source_parts = []
        
        if 'pdf_name' in metadata:
            source_parts.append(metadata['pdf_name'])
        
        if 'page' in metadata:
            source_parts.append(f"page {metadata['page']}")
        elif 'page_num' in metadata:
            source_parts.append(f"page {metadata['page_num']}")
        
        if source_parts:
            priority_sources.append(", ".join(source_parts))
    
    return list(set(priority_sources))  # Supprimer les doublons


# =============================================================================
# CONFIGURATION DU WORKFLOW
# =============================================================================

workflow = StateGraph(GraphState, input=InputState, config_schema=RagConfiguration)

# Define the nodes
workflow.add_node("retrieve", retrieve)
workflow.add_node("generate", generate)

# Build graph
workflow.add_edge(START, "retrieve")
workflow.add_edge("retrieve", "generate")
workflow.add_edge("generate", END)

# Compile
graph = workflow.compile()
graph.name = "ImprovedSimpleRag"