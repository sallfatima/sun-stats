# =============================================================================
# FICHIER: src/simple_rag/graph.py
# =============================================================================

"""
Syst√®me RAG simple am√©lior√© pour l'ANSD avec support du contenu visuel.
"""

from typing import Dict, List, Any, Tuple
import re

from langchain import hub
from langchain_core.messages import HumanMessage, AIMessage
from langchain_core.prompts import PromptTemplate
from langchain.prompts import ChatPromptTemplate

from langgraph.graph import END, START, StateGraph

from shared import retrieval
from shared.utils import load_chat_model
from simple_rag.configuration import RagConfiguration
from simple_rag.state import GraphState, InputState

# =============================================================================
# PROMPT SYSTEM AM√âLIOR√â POUR L'ANSD
# =============================================================================

IMPROVED_ANSD_SYSTEM_PROMPT = """Vous √™tes un expert statisticien de l'ANSD (Agence Nationale de la Statistique et de la D√©mographie du S√©n√©gal), sp√©cialis√© dans l'analyse de donn√©es d√©mographiques, √©conomiques et sociales du S√©n√©gal.

MISSION PRINCIPALE :
R√©pondre de mani√®re compl√®te et approfondie aux questions sur les statistiques du S√©n√©gal en utilisant PRIORITAIREMENT les documents fournis et en compl√©tant avec vos connaissances des publications officielles de l'ANSD.

SOURCES AUTORIS√âES :
‚úÖ Documents fournis dans le contexte (PRIORIT√â ABSOLUE)
‚úÖ Connaissances des rapports officiels ANSD publi√©s
‚úÖ Donn√©es du site officiel ANSD (www.ansd.sn)
‚úÖ Publications officielles des enqu√™tes ANSD (RGPH, EDS, ESPS, EHCVM, ENES)
‚úÖ Comptes nationaux et statistiques √©conomiques officielles du S√©n√©gal
‚úÖ Projections d√©mographiques officielles de l'ANSD

‚ùå SOURCES INTERDITES :
‚ùå Donn√©es d'autres pays pour combler les lacunes
‚ùå Estimations personnelles non bas√©es sur les sources ANSD
‚ùå Informations non officielles ou de sources tierces
‚ùå Projections personnelles non document√©es

R√àGLES DE R√âDACTION :
‚úÖ R√©ponse directe : SANS limitation de phrases - d√©veloppez autant que n√©cessaire
‚úÖ Contexte additionnel : SANS limitation - incluez toutes les informations pertinentes
‚úÖ Citez TOUJOURS vos sources pr√©cises (document + page ou publication ANSD)
‚úÖ Distinguez clairement les donn√©es des documents fournis vs connaissances ANSD
‚úÖ Donnez les chiffres EXACTS quand disponibles
‚úÖ Pr√©cisez SYST√âMATIQUEMENT les ann√©es de r√©f√©rence
‚úÖ Mentionnez les m√©thodologies d'enqu√™te

FORMAT DE R√âPONSE OBLIGATOIRE :

**R√âPONSE DIRECTE :**
[D√©veloppez la r√©ponse de mani√®re compl√®te et d√©taill√©e, sans limitation de longueur. Incluez tous les √©l√©ments pertinents pour une compr√©hension approfondie du sujet.]

**DONN√âES PR√âCISES :**
- Chiffres cl√©s : [valeurs exactes avec unit√©s]
- Ann√©es de r√©f√©rence : [p√©riodes des donn√©es]
- M√©thodologie : [type d'enqu√™te, √©chantillon, m√©thode]
- Couverture g√©ographique : [nationale, r√©gionale, urbain/rural]

**CONTEXTE ADDITIONNEL :**
[Informations compl√©mentaires, √©volutions, comparaisons, explications m√©thodologiques]

**SOURCES :**
[Liste pr√©cise des documents et pages consult√©s]

Contexte: {context}"""

# =============================================================================
# FONCTIONS UTILITAIRES POUR LE SCORING ET LE PR√âTRAITEMENT
# =============================================================================

def preprocess_query(query: str) -> str:
    """
    Pr√©traite la requ√™te utilisateur pour am√©liorer la recherche.
    
    Args:
        query: Requ√™te originale de l'utilisateur
        
    Returns:
        Requ√™te enrichie avec synonymes et termes ANSD
    """
    # Synonymes sp√©cifiques ANSD
    ansd_synonyms = {
        'population': ['habitants', 'd√©mographie', 'peuplement', 'r√©sidents'],
        'm√©nages': ['foyers', 'familles', 'unit√©s r√©sidentielles'],
        'pauvret√©': ['indigence', 'pr√©carit√©', 'conditions de vie'],
        'emploi': ['travail', 'activit√© √©conomique', 'occupation', 'profession'],
        '√©ducation': ['scolarisation', 'alphab√©tisation', 'instruction'],
        'sant√©': ['morbidit√©', 'mortalit√©', '√©tat sanitaire'],
        'urbain': ['ville', 'citadin', 'agglom√©ration'],
        'rural': ['campagne', 'agricole', 'villageois'],
        'r√©gion': ['administrative', 'territoire', 'zone g√©ographique'],
        'taux': ['pourcentage', 'proportion', 'ratio'],
        '√©volution': ['tendance', 'progression', 'changement'],
        'r√©partition': ['distribution', 'ventilation', 'structure']
    }
    
    # Enrichir la requ√™te
    enriched_terms = [query.lower()]
    
    for keyword, synonyms in ansd_synonyms.items():
        if keyword in query.lower():
            enriched_terms.extend(synonyms[:2])  # Ajouter 2 synonymes max
    
    # Ajouter des termes contextuels ANSD
    if any(term in query.lower() for term in ['population', 'habitants', 'recensement']):
        enriched_terms.append('rgph')
    
    if any(term in query.lower() for term in ['pauvret√©', 'conditions', 'vie']):
        enriched_terms.append('esps ehcvm')
    
    if any(term in query.lower() for term in ['emploi', 'ch√¥mage', 'activit√©']):
        enriched_terms.append('enes')
    
    if any(term in query.lower() for term in ['sant√©', 'd√©mographique']):
        enriched_terms.append('eds')
    
    return ' '.join(enriched_terms)


def score_documents_relevance(documents: List[Any], query: str) -> List[Tuple[float, Any]]:
    """
    Score les documents selon leur pertinence pour la requ√™te.
    
    Args:
        documents: Liste des documents √† scorer
        query: Requ√™te originale
        
    Returns:
        Liste de tuples (score, document) tri√©e par score d√©croissant
    """
    scored_documents = []
    query_lower = query.lower()
    
    # Mots-cl√©s importants pour l'ANSD
    important_keywords = [
        'population', 'm√©nages', 'pauvret√©', 'emploi', '√©ducation', 
        'sant√©', 'r√©gion', 'urbain', 'rural', 'taux', 'pourcentage',
        'rgph', 'eds', 'esps', 'ehcvm', 'enes', 'ansd'
    ]
    
    for doc in documents:
        score = 0
        content = getattr(doc, 'page_content', '').lower()
        metadata = getattr(doc, 'metadata', {})
        
        # Score bas√© sur les mots-cl√©s dans le contenu
        for keyword in important_keywords:
            if keyword in query_lower and keyword in content:
                score += 5
        
        # Score bas√© sur les m√©tadonn√©es
        if 'survey_type' in metadata:
            survey_type = metadata['survey_type'].lower()
            if survey_type in query_lower:
                score += 10
        
        # Score bas√© sur le type de document
        doc_type = metadata.get('type', '')
        if doc_type in ['visual_chart', 'visual_table']:
            score += 8  # Bonus pour le contenu visuel
        
        # Score bas√© sur la correspondance textuelle g√©n√©rale
        query_words = query_lower.split()
        for word in query_words:
            if len(word) > 3:
                score += content.count(word) * 2
        
        scored_documents.append((score, doc))
    
    # Trier par score d√©croissant
    scored_documents.sort(key=lambda x: x[0], reverse=True)
    return scored_documents


def format_docs_with_rich_metadata(docs: List[Any]) -> str:
    """
    Formate les documents avec m√©tadonn√©es enrichies pour le prompt.
    
    Args:
        docs: Documents √† formater
        
    Returns:
        Contexte format√© avec m√©tadonn√©es riches
    """
    if not docs:
        return "‚ùå Aucun document pertinent trouv√© dans la base de donn√©es ANSD."
    
    formatted_parts = []
    
    for i, doc in enumerate(docs, 1):
        # Extraction des m√©tadonn√©es
        metadata = doc.metadata if hasattr(doc, 'metadata') else {}
        
        # Informations sur la source
        source_info = []
        if 'source' in metadata:
            source_info.append(f"üìÑ Source: {metadata['source']}")
        if 'pdf_name' in metadata:
            source_info.append(f"üìã Document: {metadata['pdf_name']}")
        if 'page_num' in metadata:
            source_info.append(f"üìñ Page: {metadata['page_num']}")
        if 'page' in metadata:
            source_info.append(f"üìñ Page: {metadata['page']}")
        if 'type' in metadata:
            source_info.append(f"üîñ Type: {metadata['type']}")
        if 'caption' in metadata:
            source_info.append(f"üìä Titre: {metadata['caption']}")
        
        # En-t√™te du document
        header = f"\n{'='*50}\nüìä DOCUMENT ANSD #{i}\n"
        if source_info:
            header += "\n".join(source_info) + "\n"
        header += f"{'='*50}\n"
        
        # Contenu avec nettoyage
        content = doc.page_content.strip()
        
        # D√©tecter le type de contenu
        content_indicators = []
        if any(keyword in content.lower() for keyword in ['rgph', 'recensement']):
            content_indicators.append("üèòÔ∏è RECENSEMENT")
        if any(keyword in content.lower() for keyword in ['eds', 'd√©mographique']):
            content_indicators.append("üë• D√âMOGRAPHIE")
        if any(keyword in content.lower() for keyword in ['esps', 'pauvret√©']):
            content_indicators.append("üí∞ PAUVRET√â")
        if any(keyword in content.lower() for keyword in ['√©conomie', 'pib']):
            content_indicators.append("üìà √âCONOMIE")
        if metadata.get('type') in ['visual_chart', 'visual_table']:
            content_indicators.append("üé® VISUEL")
        
        if content_indicators:
            header += f"üè∑Ô∏è Cat√©gories: {' | '.join(content_indicators)}\n{'-'*50}\n"
        
        formatted_parts.append(f"{header}\n{content}\n")
    
    return "\n".join(formatted_parts)


def analyze_retrieved_documents(documents: List[Any]) -> Tuple[List[Any], List[Any]]:
    """
    Analyse et s√©pare les documents textuels des documents visuels.
    
    Args:
        documents: Liste des documents r√©cup√©r√©s
        
    Returns:
        Tuple (documents_textuels, documents_visuels)
    """
    text_docs = []
    visual_docs = []
    
    for doc in documents:
        metadata = getattr(doc, 'metadata', {})
        doc_type = metadata.get('type', '')
        source_type = metadata.get('source_type', '')
        
        # Identifier les documents visuels
        if (doc_type in ['visual_chart', 'visual_table'] or 
            source_type == 'visual' or
            'image_path' in metadata or 
            'table_path' in metadata):
            visual_docs.append(doc)
        else:
            text_docs.append(doc)
    
    return text_docs, visual_docs


def enrich_query_for_visual_content(question: str) -> str:
    """
    Enrichit la requ√™te pour am√©liorer la r√©cup√©ration de contenu visuel.
    
    Args:
        question: Question originale de l'utilisateur
        
    Returns:
        Requ√™te enrichie pour la recherche
    """
    # Mots-cl√©s qui sugg√®rent du contenu visuel
    visual_keywords = {
        'r√©partition': ['graphique', 'diagramme', 'pourcentage'],
        '√©volution': ['courbe', 'tendance', 'graphique'],
        'comparaison': ['tableau', 'donn√©es', 'statistiques'],
        'taux': ['pourcentage', 'graphique', 'donn√©es'],
        'structure': ['r√©partition', 'graphique', 'diagramme'],
        'donn√©es': ['tableau', 'statistiques', 'chiffres'],
        'statistiques': ['tableau', 'donn√©es', 'chiffres'],
        'pourcentage': ['r√©partition', 'graphique', 'diagramme']
    }
    
    # Construire la requ√™te enrichie
    query_parts = [question]
    
    question_lower = question.lower()
    
    # Ajouter des termes de recherche visuelle pertinents
    for keyword, related_terms in visual_keywords.items():
        if keyword in question_lower:
            query_parts.extend(related_terms[:2])  # Ajouter 2 termes li√©s max
    
    # Ajouter des termes g√©n√©riques pour le contenu visuel
    if any(term in question_lower for term in ['r√©partition', '√©volution', 'taux', 'pourcentage']):
        query_parts.append('visual_chart')
        query_parts.append('graphique')
    
    if any(term in question_lower for term in ['donn√©es', 'tableau', 'statistiques']):
        query_parts.append('visual_table')
        query_parts.append('tableau')
    
    return ' '.join(query_parts)


# =============================================================================
# FONCTIONS PRINCIPALES DU WORKFLOW
# =============================================================================

async def retrieve(state: GraphState, *, config: RagConfiguration):
    """R√©cup√©ration am√©lior√©e avec support du contenu visuel et scoring intelligent."""
    
    print("üîç ---RETRIEVE AVEC SUPPORT VISUEL AM√âLIOR√â---")
    
    # Extraire la question
    last_message = state.messages[-1]
    question = last_message.content if hasattr(last_message, 'content') else str(last_message)
    
    print(f"‚ùì Question originale: {question}")
    
    # Enrichir la requ√™te pour le contenu visuel
    enriched_query = enrich_query_for_visual_content(question)
    
    # Pr√©traitement additionnel
    processed_query = preprocess_query(enriched_query)
    
    print(f"üîç Requ√™te enrichie: {processed_query}")
    
    # Configuration de recherche optimis√©e
    with retrieval.make_retriever(config) as retriever:
        # Recherche avec la requ√™te enrichie
        documents = retriever.invoke(processed_query)
    
    print(f"üìÑ Documents r√©cup√©r√©s: {len(documents)}")
    
    # Analyser et classer les documents
    text_docs, visual_docs = analyze_retrieved_documents(documents)
    
    print(f"üìù Documents textuels: {len(text_docs)}")
    print(f"üé® Documents visuels: {len(visual_docs)}")
    
    # Afficher les d√©tails des documents visuels trouv√©s
    if visual_docs:
        print("üé® √âl√©ments visuels d√©tect√©s:")
        for i, doc in enumerate(visual_docs, 1):
            metadata = getattr(doc, 'metadata', {})
            doc_type = metadata.get('type', 'unknown')
            caption = metadata.get('caption', 'Sans titre')
            print(f"   {i}. {doc_type}: {caption}")
    
    # Combiner tous les documents pour le processing suivant
    all_documents = text_docs + visual_docs
    
    # Appliquer un scoring intelligent pour prioriser les documents pertinents
    scored_documents = score_documents_relevance(all_documents, question)
    
    # Prendre les 20 meilleurs documents
    best_documents = [doc for score, doc in scored_documents[:20]]
    
    print(f"‚úÖ Documents s√©lectionn√©s apr√®s scoring: {len(best_documents)}")
    
    return {"documents": best_documents, "messages": state.messages}


async def generate(state: GraphState, *, config: RagConfiguration):
    """G√©n√©ration avec support d'affichage automatique du contenu visuel."""
    
    print("ü§ñ ---GENERATE AVEC SUPPORT VISUEL---")
    
    messages = state.messages
    documents = state.documents
    
    configuration = RagConfiguration.from_runnable_config(config)
    model = load_chat_model(configuration.model)
    
    # Extraire la question
    user_question = ""
    for msg in messages:
        if hasattr(msg, 'content'):
            user_question = msg.content
            break
    
    print(f"‚ùì Question: {user_question}")
    print(f"üìÑ Total documents: {len(documents)}")
    
    # S√©parer le contenu textuel et visuel
    text_docs, visual_docs = analyze_retrieved_documents(documents)
    
    print(f"üìù Documents textuels pour g√©n√©ration: {len(text_docs)}")
    print(f"üé® Documents visuels d√©tect√©s: {len(visual_docs)}")
    
    # G√©n√©rer la r√©ponse bas√©e sur le contenu textuel et visuel combin√©
    prompt = ChatPromptTemplate.from_messages([
        ("system", IMPROVED_ANSD_SYSTEM_PROMPT),
        ("human", "{question}")
    ])
    
    # Utiliser tous les documents (textuels + visuels) pour le contexte
    context = format_docs_with_rich_metadata(documents)
    
    response = await (prompt | model).ainvoke({
        "context": context,
        "question": user_question
    })
    
    textual_response = response.content
    
    # Enrichir la r√©ponse si du contenu visuel est disponible
    if visual_docs:
        # Ajouter une mention des √©l√©ments visuels disponibles
        visual_summary = create_visual_content_summary(visual_docs)
        
        enhanced_response = f"""{textual_response}

üìä **√âl√©ments visuels disponibles :**
{visual_summary}

*Les graphiques et tableaux correspondants seront affich√©s automatiquement dans le chat.*"""
        
        final_response = enhanced_response
        
        # Marquer la r√©ponse avec des m√©tadonn√©es pour l'affichage visuel
        response_metadata = {
            'has_visual_content': True,
            'visual_count': len(visual_docs),
            'visual_types': [doc.metadata.get('type', 'unknown') for doc in visual_docs]
        }
        
    else:
        final_response = textual_response
        response_metadata = {'has_visual_content': False}
    
    # Cr√©er la r√©ponse finale
    enhanced_response = AIMessage(
        content=final_response,
        response_metadata=response_metadata
    )
    
    print(f"‚úÖ R√©ponse g√©n√©r√©e avec {len(visual_docs)} √©l√©ments visuels")
    
    return {"messages": [enhanced_response], "documents": documents}


def create_visual_content_summary(visual_docs: List[Any]) -> str:
    """
    Cr√©e un r√©sum√© textuel des √©l√©ments visuels disponibles.
    
    Args:
        visual_docs: Documents visuels
        
    Returns:
        R√©sum√© format√© des √©l√©ments visuels
    """
    summary_parts = []
    
    charts_count = 0
    tables_count = 0
    
    for i, doc in enumerate(visual_docs, 1):
        metadata = getattr(doc, 'metadata', {})
        doc_type = metadata.get('type', 'unknown')
        caption = metadata.get('caption', f'√âl√©ment {i}')
        pdf_name = metadata.get('pdf_name', 'Document ANSD')
        page = metadata.get('page', '')
        
        if doc_type == 'visual_chart':
            charts_count += 1
            icon = "üìä"
        elif doc_type == 'visual_table':
            tables_count += 1
            icon = "üìã"
        else:
            icon = "üìÑ"
        
        source_info = f"{pdf_name}"
        if page:
            source_info += f" (page {page})"
        
        summary_parts.append(f"{icon} **{caption}** - *{source_info}*")
    
    # Ajouter un r√©sum√© en en-t√™te
    summary_header = []
    if charts_count > 0:
        summary_header.append(f"{charts_count} graphique(s)")
    if tables_count > 0:
        summary_header.append(f"{tables_count} tableau(x)")
    
    if summary_header:
        header = " et ".join(summary_header)
        summary_parts.insert(0, f"*{header} trouv√©(s) :*\n")
    
    return "\n".join(summary_parts)


# =============================================================================
# FONCTIONS DE DEBUG ET DIAGNOSTIC (CONSERV√âES DE VOTRE CODE)
# =============================================================================

def diagnose_sources(documents: List[Any], response_content: str) -> None:
    """Diagnostic des sources pour d√©boguer."""
    
    print("\nüîç DIAGNOSTIC DES SOURCES:")
    print("="*50)
    
    # Analyser les documents
    print(f"üìÑ Documents fournis: {len(documents)}")
    for i, doc in enumerate(documents, 1):
        metadata = doc.metadata if hasattr(doc, 'metadata') else {}
        print(f"   Document {i}:")
        print(f"      pdf_name: {metadata.get('pdf_name', 'Non d√©fini')}")
        print(f"      page_num: {metadata.get('page_num', 'Non d√©fini')}")
        print(f"      source: {metadata.get('source', 'Non d√©fini')}")
        print(f"      type: {metadata.get('type', 'Non d√©fini')}")
    
    print("="*50)


def extract_priority_sources(documents: List[Any]) -> List[str]:
    """Extrait les sources prioritaires des documents."""
    
    priority_sources = []
    
    for doc in documents:
        metadata = getattr(doc, 'metadata', {})
        
        # Construire la source √† partir des m√©tadonn√©es
        source_parts = []
        
        if 'pdf_name' in metadata:
            source_parts.append(metadata['pdf_name'])
        
        if 'page' in metadata:
            source_parts.append(f"page {metadata['page']}")
        elif 'page_num' in metadata:
            source_parts.append(f"page {metadata['page_num']}")
        
        if source_parts:
            priority_sources.append(", ".join(source_parts))
    
    return list(set(priority_sources))  # Supprimer les doublons


def use_document_sources(response_content: str, priority_sources: List[str]) -> str:
    """Utilise les sources des documents dans la r√©ponse."""
    
    if priority_sources:
        sources_section = f"\n\nüìö **Sources consult√©es :**\n"
        for i, source in enumerate(priority_sources[:5], 1):  # Limiter √† 5 sources
            sources_section += f"‚Ä¢ {source}\n"
        
        return response_content + sources_section
    
    return response_content


def preserve_llm_sources(response_content: str) -> str:
    """Pr√©serve les sources g√©n√©r√©es par le LLM."""
    return response_content


# =============================================================================
# VERSION DEBUG AVEC DIAGNOSTIC COMPLET (CONSERV√âE)
# =============================================================================

async def generate_with_debug(state: GraphState, *, config: RagConfiguration):
    """Version avec diagnostic pour d√©boguer les sources."""
    
    print("ü§ñ ---GENERATE AVEC DEBUG SOURCES---")
    
    messages = state.messages
    documents = state.documents
    
    prompt = ChatPromptTemplate.from_messages([
        ("system", IMPROVED_ANSD_SYSTEM_PROMPT),
        ("placeholder", "{messages}")
    ])
    
    configuration = RagConfiguration.from_runnable_config(config)
    model = load_chat_model(configuration.model)
    context = format_docs_with_rich_metadata(documents)
    
    try:
        rag_chain = prompt | model
        response = await rag_chain.ainvoke({
            "context": context,
            "messages": messages
        })
        
        response_content = response.content
        
        # DIAGNOSTIC COMPLET
        diagnose_sources(documents, response_content)
        
        # Appliquer la logique de priorit√©
        priority_sources = extract_priority_sources(documents)
        
        if priority_sources:
            print("üîù STRAT√âGIE: Utilisation des sources de documents")
            final_response = use_document_sources(response_content, priority_sources)
        else:
            print("ü§ñ STRAT√âGIE: Conservation des sources LLM")
            final_response = preserve_llm_sources(response_content)
        
        enhanced_response = AIMessage(content=final_response)
        
        return {"messages": [enhanced_response], "documents": documents}
        
    except Exception as e:
        print(f"‚ùå Erreur: {e}")
        fallback = AIMessage(content="‚ùå Erreur technique ANSD.")
        return {"messages": [fallback], "documents": documents}


# =============================================================================
# CONFIGURATION DU WORKFLOW
# =============================================================================

workflow = StateGraph(GraphState, input=InputState, config_schema=RagConfiguration)

# Define the nodes
workflow.add_node("retrieve", retrieve)
workflow.add_node("generate", generate)

# Build graph
workflow.add_edge(START, "retrieve")
workflow.add_edge("retrieve", "generate")
workflow.add_edge("generate", END)

# Compile
graph = workflow.compile()
graph.name = "ImprovedSimpleRag"