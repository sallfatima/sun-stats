# =============================================================================
# FICHIER 1: src/simple_rag/graph.py
# =============================================================================
# REMPLACEZ TOUT LE CONTENU DE CE FICHIER PAR LE CODE CI-DESSOUS

### Nodes

from langchain import hub
from langchain_core.messages import HumanMessage, AIMessage

from langgraph.graph import END, START, StateGraph

from shared import retrieval
from shared.utils import load_chat_model
from simple_rag.configuration import RagConfiguration
from simple_rag.state import GraphState, InputState
from langchain_core.prompts import PromptTemplate
from langchain.prompts import ChatPromptTemplate
import re

# =============================================================================
# PROMPT SYSTEM AM√âLIOR√â POUR L'ANSD
# =============================================================================

IMPROVED_ANSD_SYSTEM_PROMPT = """Vous √™tes un expert statisticien de l'ANSD (Agence Nationale de la Statistique et de la D√©mographie du S√©n√©gal), sp√©cialis√© dans l'analyse de donn√©es d√©mographiques, √©conomiques et sociales du S√©n√©gal.

MISSION PRINCIPALE :
R√©pondre de mani√®re compl√®te et approfondie aux questions sur les statistiques du S√©n√©gal en utilisant PRIORITAIREMENT les documents fournis et en compl√©tant avec vos connaissances des publications officielles de l'ANSD.

SOURCES AUTORIS√âES :
‚úÖ Documents fournis dans le contexte (PRIORIT√â ABSOLUE)
‚úÖ Connaissances des rapports officiels ANSD publi√©s
‚úÖ Donn√©es du site officiel ANSD (www.ansd.sn)
‚úÖ Publications officielles des enqu√™tes ANSD (RGPH, EDS, ESPS, EHCVM, ENES)
‚úÖ Comptes nationaux et statistiques √©conomiques officielles du S√©n√©gal
‚úÖ Projections d√©mographiques officielles de l'ANSD

‚ùå SOURCES INTERDITES :
‚ùå Donn√©es d'autres pays pour combler les lacunes
‚ùå Estimations personnelles non bas√©es sur les sources ANSD
‚ùå Informations non officielles ou de sources tierces
‚ùå Projections personnelles non document√©es

R√àGLES DE R√âDACTION :
‚úÖ R√©ponse directe : SANS limitation de phrases - d√©veloppez autant que n√©cessaire
‚úÖ Contexte additionnel : SANS limitation - incluez toutes les informations pertinentes
‚úÖ Citez TOUJOURS vos sources pr√©cises (document + page ou publication ANSD)
‚úÖ Distinguez clairement les donn√©es des documents fournis vs connaissances ANSD
‚úÖ Donnez les chiffres EXACTS quand disponibles
‚úÖ Pr√©cisez SYST√âMATIQUEMENT les ann√©es de r√©f√©rence
‚úÖ Mentionnez les m√©thodologies d'enqu√™te

FORMAT DE R√âPONSE OBLIGATOIRE :

**R√âPONSE DIRECTE :**
[D√©veloppez la r√©ponse de mani√®re compl√®te et d√©taill√©e, sans limitation de longueur. Incluez tous les √©l√©ments pertinents pour une compr√©hension approfondie du sujet. Vous pouvez utiliser plusieurs paragraphes et d√©velopper les aspects importants.]

**DONN√âES PR√âCISES :**
- Chiffre exact : [valeur exacte avec unit√©]
- Ann√©e de r√©f√©rence : [ann√©e pr√©cise]
- Source : [nom exact du document, page X OU publication ANSD officielle]
- M√©thodologie : [enqu√™te/recensement utilis√©]

**CONTEXTE ADDITIONNEL :**
[D√©veloppez largement avec toutes les informations compl√©mentaires pertinentes, sans limitation de longueur. Incluez :
- √âvolutions temporelles et tendances
- Comparaisons r√©gionales ou d√©mographiques
- M√©thodologies d√©taill√©es
- Contexte socio-√©conomique
- Implications et analyses
- Donn√©es connexes des autres enqu√™tes ANSD
- Informations contextuelles des rapports officiels ANSD
Organisez en paragraphes clairs et d√©veloppez chaque aspect important.]

**LIMITATIONS/NOTES :**
[Pr√©cautions d'interpr√©tation, changements m√©thodologiques, d√©finitions sp√©cifiques]

INSTRUCTIONS POUR LES SOURCES :
- Documents fournis : "Document.pdf, page X"
- Connaissances ANSD officielles : "ANSD - [Nom de l'enqu√™te/rapport], [ann√©e]"
- Site officiel : "Site officiel ANSD (www.ansd.sn)"
- Distinguez clairement : "Selon les documents fournis..." vs "D'apr√®s les publications ANSD..."

Si aucune information n'est disponible (documents + connaissances ANSD) :
"‚ùå Cette information n'est pas disponible dans les documents fournis ni dans les publications ANSD consult√©es. 
üìû Pour obtenir cette donn√©e sp√©cifique, veuillez consulter directement l'ANSD (www.ansd.sn) ou leurs services techniques sp√©cialis√©s."

DOCUMENTS ANSD DISPONIBLES :
{context}

Analysez maintenant ces documents et r√©pondez √† la question de l'utilisateur de mani√®re compl√®te et approfondie."""


# =============================================================================
# FONCTIONS UTILITAIRES
# =============================================================================

def preprocess_query_enhanced(query: str) -> str:
    """Pr√©traitement avanc√© des requ√™tes pour am√©liorer la recherche dans les documents ANSD."""
    
    # Normalisation de base
    query_lower = query.lower().strip()
    
    # Dictionnaire de synonymes sp√©cifiques √† l'ANSD
    ansd_synonyms = {
        # D√©mographie
        "population": ["habitants", "d√©mographie", "recensement", "rgph", "nombre d'habitants"],
        "natalit√©": ["naissances", "taux de natalit√©", "f√©condit√©"],
        "mortalit√©": ["d√©c√®s", "taux de mortalit√©", "esp√©rance de vie"],
        
        # √âconomie
        "pauvret√©": ["pauvre", "indigence", "vuln√©rabilit√©", "esps", "ehcvm"],
        "√©conomie": ["pib", "croissance", "√©conomique", "revenus", "production"],
        "emploi": ["ch√¥mage", "travail", "activit√© √©conomique", "enes"],
        
        # √âducation
        "√©ducation": ["√©cole", "alphab√©tisation", "scolarisation", "enseignement"],
        "alphab√©tisation": ["lecture", "√©criture", "alphab√®te", "analphab√®te"],
        
        # Sant√©
        "sant√©": ["mortalit√©", "morbidit√©", "eds", "vaccination", "nutrition"],
        "maternelle": ["maternit√©", "accouchement", "sage-femme"],
        
        # G√©ographie
        "r√©gion": ["d√©partement", "commune", "arrondissement", "localit√©"],
        "rural": ["campagne", "village", "agriculture"],
        "urbain": ["ville", "dakar", "centre urbain"],
        
        # Enqu√™tes sp√©cifiques
        "rgph": ["recensement", "population", "habitat"],
        "eds": ["d√©mographique", "sant√©", "enqu√™te"],
        "esps": ["pauvret√©", "conditions de vie"],
        "ehcvm": ["m√©nages", "budget", "consommation"],
        "enes": ["emploi", "activit√©", "ch√¥mage"]
    }
    
    # Enrichir la requ√™te avec des synonymes pertinents
    enriched_terms = []
    for key, values in ansd_synonyms.items():
        if key in query_lower:
            # Ajouter les 2 synonymes les plus pertinents
            enriched_terms.extend(values[:2])
    
    # Ajouter des termes contextuels ANSD
    context_terms = []
    if any(word in query_lower for word in ["taux", "pourcentage", "%"]):
        context_terms.append("indicateur")
    if any(word in query_lower for word in ["2023", "2024", "r√©cent", "dernier"]):
        context_terms.append("derni√®res donn√©es")
    
    # Construire la requ√™te enrichie
    final_query = query
    if enriched_terms:
        final_query += " " + " ".join(enriched_terms)
    if context_terms:
        final_query += " " + " ".join(context_terms)
    
    return final_query


def format_docs_with_metadata(docs) -> str:
    """Formatage avanc√© des documents avec m√©tadonn√©es enrichies pour l'ANSD."""
    
    if not docs:
        return "‚ùå Aucun document pertinent trouv√© dans la base de donn√©es ANSD."
    
    formatted_parts = []
    
    for i, doc in enumerate(docs, 1):
        # Extraction des m√©tadonn√©es
        metadata = doc.metadata if hasattr(doc, 'metadata') else {}
        
        # Informations sur la source
        source_info = []
        if 'source' in metadata:
            source_info.append(f"üìÑ Source: {metadata['source']}")
        if 'pdf_name' in metadata:
            source_info.append(f"üìã Document: {metadata['pdf_name']}")
        if 'page_num' in metadata:
            source_info.append(f"üìñ Page: {metadata['page_num']}")
        if 'indexed_at' in metadata:
            source_info.append(f"üïê Index√©: {metadata['indexed_at'][:10]}")
        
        # En-t√™te du document
        header = f"\n{'='*50}\nüìä DOCUMENT ANSD #{i}\n"
        if source_info:
            header += "\n".join(source_info) + "\n"
        header += f"{'='*50}\n"
        
        # Contenu avec nettoyage
        content = doc.page_content.strip()
        
        # D√©tecter le type de contenu
        content_indicators = []
        if any(keyword in content.lower() for keyword in ['rgph', 'recensement']):
            content_indicators.append("üèòÔ∏è RECENSEMENT")
        if any(keyword in content.lower() for keyword in ['eds', 'd√©mographique']):
            content_indicators.append("üë• D√âMOGRAPHIE")
        if any(keyword in content.lower() for keyword in ['esps', 'pauvret√©']):
            content_indicators.append("üí∞ PAUVRET√â")
        if any(keyword in content.lower() for keyword in ['√©conomie', 'pib']):
            content_indicators.append("üìà √âCONOMIE")
        
        if content_indicators:
            header += f"üè∑Ô∏è Cat√©gories: {' | '.join(content_indicators)}\n{'-'*50}\n"
        
        formatted_parts.append(f"{header}\n{content}\n")
    
    return "\n".join(formatted_parts)

# =============================================================================
# FONCTIONS PRINCIPALES AM√âLIOR√âES
# =============================================================================

async def retrieve(state: GraphState, *, config: RagConfiguration) -> dict[str, list[str] | str]: 
    """Fonction de r√©cup√©ration am√©lior√©e avec pr√©traitement et scoring."""
    
    print("üîç ---RETRIEVE AM√âLIOR√â---")
    
    # Extraction et pr√©traitement de la question
    question = " ".join(msg.content for msg in state.messages if isinstance(msg, HumanMessage))
    if not question:
        raise ValueError("‚ùå Question vide d√©tect√©e")
    
    # Pr√©traitement avanc√©
    processed_question = preprocess_query_enhanced(question)
    print(f"üìù Question originale: {question}")
    print(f"üîß Question enrichie: {processed_question}")
    
    # R√©cup√©ration avec gestion d'erreurs
    try:
        async with retrieval.make_retriever(config) as retriever:
            documents = await retriever.ainvoke(processed_question)
        
        print(f"üìö Documents r√©cup√©r√©s: {len(documents)}")
        
        if not documents:
            print("‚ö†Ô∏è Aucun document trouv√©, essai avec la question originale...")
            async with retrieval.make_retriever(config) as retriever:
                documents = await retriever.ainvoke(question)
        
    except Exception as e:
        print(f"‚ùå Erreur lors de la r√©cup√©ration: {e}")
        return {"documents": [], "messages": state.messages}
    
    # Scoring et filtrage avanc√©
    if documents:
        scored_documents = []
        question_keywords = set(question.lower().split())
        
        for doc in documents:
            content_lower = doc.page_content.lower()
            score = 0
            
            # Scoring bas√© sur les mots-cl√©s
            for word in question_keywords:
                if len(word) > 3:  # Ignorer les mots tr√®s courts
                    score += content_lower.count(word) * 2
            
            # Bonus pour les termes ANSD sp√©cifiques
            ansd_terms = ['rgph', 'eds', 'esps', 'ehcvm', 'enes', 'ansd', 's√©n√©gal']
            for term in ansd_terms:
                if term in content_lower:
                    score += 5
            
            # Bonus pour les donn√©es num√©riques
            if re.search(r'\d+[.,]\d+|\d+\s*%|\d+\s*(millions?|milliards?)', content_lower):
                score += 3
            
            scored_documents.append((score, doc))
        
        # Trier et s√©lectionner les meilleurs
        scored_documents.sort(key=lambda x: x[0], reverse=True)
        best_documents = [doc for score, doc in scored_documents[:15]]  # Top 15
        
        print(f"‚úÖ Documents s√©lectionn√©s apr√®s scoring: {len(best_documents)}")
        
        return {"documents": best_documents, "messages": state.messages}
    
    else:
        print("‚ùå Aucun document pertinent trouv√©")
        return {"documents": [], "messages": state.messages}

# =============================================================================
# LOGIQUE S√âQUENTIELLE : DOCUMENTS ‚Üí ANSD EXTERNE
# =============================================================================

# REMPLACEZ votre fonction generate dans src/simple_rag/graph.py par celle-ci :

async def generate(state: GraphState, *, config: RagConfiguration):
    """G√©n√©ration avec logique s√©quentielle CORRIG√âE."""
    
    print("ü§ñ ---GENERATE AVEC LOGIQUE S√âQUENTIELLE CORRIG√âE---")
    
    messages = state.messages
    documents = state.documents
    
    configuration = RagConfiguration.from_runnable_config(config)
    model = load_chat_model(configuration.model)
    
    # Extraire la question
    user_question = ""
    for msg in messages:
        if hasattr(msg, 'content'):
            user_question = msg.content
            break
    
    print(f"‚ùì Question: {user_question}")
    print(f"üìÑ Documents disponibles: {len(documents)}")
    
    # =============================================================================
    # √âTAPE 1 : ESSAYER AVEC LES DOCUMENTS INDEX√âS
    # =============================================================================
    
    print("\nüîç √âTAPE 1 : Recherche dans les documents index√©s...")
    
    if documents:
        # Prompt AM√âLIOR√â pour mieux utiliser les documents
        prompt_documents_only = ChatPromptTemplate.from_messages([
            ("system", """Vous √™tes un expert statisticien de l'ANSD. 

Analysez les documents fournis et r√©pondez √† la question en utilisant EXCLUSIVEMENT ces documents.

R√àGLES :
‚úÖ Utilisez TOUTES les informations pertinentes trouv√©es dans les documents
‚úÖ Donnez les chiffres EXACTS trouv√©s
‚úÖ Citez les sources pr√©cises (nom du document, page)
‚úÖ D√©veloppez votre r√©ponse avec les d√©tails disponibles
‚úÖ Si vous trouvez des informations partielles, pr√©sentez-les clairement

‚ùå Seulement si VRAIMENT AUCUNE information pertinente n'est trouv√©e, r√©pondez : "INFORMATION NON DISPONIBLE"

FORMAT DE R√âPONSE :

**R√âPONSE DIRECTE :**
[R√©ponse d√©taill√©e bas√©e sur les documents trouv√©s]

**DONN√âES PR√âCISES :**
- Chiffre exact : [valeurs des documents]
- Ann√©e de r√©f√©rence : [ann√©e des documents]
- Source : [nom exact du document, page X]
- M√©thodologie : [enqu√™te/recensement des documents]

**CONTEXTE ADDITIONNEL :**
[Toutes les informations compl√©mentaires trouv√©es dans les documents]

**LIMITATIONS/NOTES :**
[Pr√©cisions sur les donn√©es si n√©cessaire]

DOCUMENTS DISPONIBLES :
{context}"""),
            ("placeholder", "{messages}")
        ])
        
        context = format_docs_with_metadata(documents)
        
        try:
            rag_chain = prompt_documents_only | model
            response_step1 = await rag_chain.ainvoke({
                "context": context,
                "messages": messages
            })
            
            response_content = response_step1.content
            
            print(f"\nüìù R√âPONSE √âTAPE 1:")
            print(f"Longueur: {len(response_content)} caract√®res")
            print(f"Aper√ßu: {response_content[:300]}...")
            
            # V√©rifier si les documents ont fourni une r√©ponse satisfaisante
            is_satisfactory = evaluate_response_quality(response_content, documents)
            
            if is_satisfactory:
                print("\n‚úÖ SUCC√àS √âTAPE 1 : R√©ponse satisfaisante trouv√©e dans les documents index√©s")
                
                # Ajouter les sources des documents
                sources_section = create_document_sources(documents, response_content)
                final_response = response_content + sources_section
                
                enhanced_response = AIMessage(content=final_response)
                return {"messages": [enhanced_response], "documents": documents}
            
            else:
                print("\n‚ö†Ô∏è √âCHEC √âTAPE 1 : R√©ponse jug√©e insuffisante")
                print("Passage √† l'√©tape 2...")
        
        except Exception as e:
            print(f"‚ùå ERREUR √âTAPE 1: {e}")
    
    else:
        print("‚ö†Ô∏è √âTAPE 1 IGNOR√âE : Aucun document disponible")
    
    
    # =============================================================================
    # √âTAPE 2 : UTILISER LES CONNAISSANCES ANSD EXTERNES
    # =============================================================================
    
    print("\nüåê √âTAPE 2 : Recherche dans les connaissances ANSD externes...")
    
    # Prompt pour utiliser les connaissances ANSD officielles
    prompt_ansd_external = ChatPromptTemplate.from_messages([
        ("system", """Vous √™tes un expert statisticien de l'ANSD avec acc√®s aux publications officielles.

Les documents index√©s n'ont pas fourni d'information satisfaisante. Utilisez maintenant vos connaissances des rapports officiels ANSD et du site officiel.

SOURCES AUTORIS√âES :
‚úÖ Rapports officiels ANSD publi√©s
‚úÖ Site officiel ANSD (www.ansd.sn)
‚úÖ Publications des enqu√™tes ANSD (RGPH, EDS, ESPS, EHCVM, ENES)
‚úÖ Comptes nationaux officiels du S√©n√©gal

FORMAT DE R√âPONSE :

**R√âPONSE DIRECTE :**
[R√©ponse bas√©e sur les connaissances ANSD officielles]

**DONN√âES PR√âCISES :**
- Chiffre exact : [valeur des rapports ANSD]
- Ann√©e de r√©f√©rence : [ann√©e pr√©cise]
- Source : [Publication ANSD officielle]
- M√©thodologie : [enqu√™te ANSD utilis√©e]

**CONTEXTE ADDITIONNEL :**
[Informations contextuelles des publications ANSD]

**LIMITATIONS/NOTES :**
[Pr√©cautions d'interpr√©tation]

IMPORTANT : Mentionnez que cette information provient des connaissances ANSD officielles, pas des documents index√©s."""),
        ("placeholder", "{messages}")
    ])
    
    try:
        rag_chain_external = prompt_ansd_external | model
        response_step2 = await rag_chain_external.ainvoke({
            "messages": messages
        })
        
        response_content = response_step2.content
        
        print("‚úÖ SUCC√àS √âTAPE 2 : R√©ponse obtenue des connaissances ANSD")
        
        # Ajouter les sources externes
        sources_section = create_external_ansd_sources(response_content)
        final_response = response_content + sources_section
        
        enhanced_response = AIMessage(content=final_response)
        return {"messages": [enhanced_response], "documents": documents}
    
    except Exception as e:
        print(f"‚ùå ERREUR √âTAPE 2: {e}")
        
        # Fallback final
        fallback_response = AIMessage(content=
            "‚ùå Informations non disponibles dans les documents index√©s et les sources ANSD consult√©es. "
            "Veuillez consulter directement l'ANSD (www.ansd.sn) pour cette information sp√©cifique."
        )
        return {"messages": [fallback_response], "documents": documents}

# =============================================================================
# FONCTIONS D'√âVALUATION ET DE SOURCES
# =============================================================================

def evaluate_response_quality(response_content, documents):
    """√âvaluation CORRIG√âE - Moins stricte pour accepter les r√©ponses des documents."""
    
    response_lower = response_content.lower()
    
    print(f"üîç √âVALUATION DE LA R√âPONSE:")
    print(f"   Longueur: {len(response_content)} caract√®res")
    print(f"   Aper√ßu: {response_content[:150]}...")
    
    # Crit√®res d'√©chec STRICTS (r√©ponse clairement insuffisante)
    failure_indicators = [
        "information non disponible",
        "cette information n'est pas disponible",
        "aucune information",
        "pas disponible dans les documents",
        "impossible de r√©pondre",
        "donn√©es non pr√©sentes",
        "ne peut pas r√©pondre",
        "informations insuffisantes"
    ]
    
    # Si contient un indicateur d'√©chec EXPLICITE
    for indicator in failure_indicators:
        if indicator in response_lower:
            print(f"   ‚ùå √âCHEC: Contient '{indicator}'")
            return False
    
    # Crit√®res de succ√®s ASSOUPLIS
    success_indicators = {
        'has_numbers': bool(re.search(r'\d+', response_content)),  # N'importe quel chiffre
        'has_content': len(response_content) > 100,  # R√©duit de 200 √† 100
        'has_words': len(response_content.split()) > 20,  # R√©duit de 30 √† 20
        'has_structure': '**' in response_content or '-' in response_content,  # Structure visible
        'mentions_documents': any(term in response_lower for term in ['chapitre', 'page', 'document', 'source']),
        'has_specific_content': any(term in response_lower for term in [
            'r√©partition', 'secteur', 'occup√©s', 'institutionnel', 'emploi', 'travail',
            'population', 'habitants', 'taux', 'pourcentage', 'statistique'
        ])
    }
    
    print(f"   üìä Crit√®res d√©taill√©s:")
    for criterion, passed in success_indicators.items():
        status = "‚úÖ" if passed else "‚ùå"
        print(f"      {status} {criterion}")
    
    success_count = sum(success_indicators.values())
    
    # SEUIL R√âDUIT : 3 crit√®res au lieu de 3 sur 6 plus stricts
    is_satisfactory = success_count >= 1
    
    print(f"   üìà Score: {success_count}/6 crit√®res")
    print(f"   üéØ R√©sultat: {'‚úÖ SATISFAISANT' if is_satisfactory else '‚ùå INSUFFISANT'}")
    
    return is_satisfactory

def create_document_sources(documents, response_content):
    """Cr√©e la section sources pour les documents index√©s."""
    
    sources_section = "\n\nüìö **Sources utilis√©es :**\n"
    
    # Extraire les documents r√©ellement pertinents
    relevant_docs = []
    response_lower = response_content.lower()
    
    for doc in documents:
        doc_content = doc.page_content.lower()
        metadata = doc.metadata if hasattr(doc, 'metadata') else {}
        
        # V√©rifier si le document a √©t√© utilis√© (overlap de contenu)
        doc_words = set(doc_content.split())
        response_words = set(response_lower.split())
        
        # Mots significatifs communs
        significant_words = {word for word in doc_words.intersection(response_words) 
                           if len(word) > 4}
        
        # Si overlap significatif OU donn√©es num√©riques communes
        doc_numbers = set(re.findall(r'\d+[.,]?\d*', doc_content))
        response_numbers = set(re.findall(r'\d+[.,]?\d*', response_lower))
        
        if len(significant_words) > 2 or doc_numbers.intersection(response_numbers):
            doc_name = metadata.get('pdf_name', 'Document ANSD')
            page_num = metadata.get('page_num', 'Non sp√©cifi√©e')
            
            if '/' in doc_name:
                doc_name = doc_name.split('/')[-1]
            
            formatted = f"{doc_name}, page {page_num}" if page_num != 'Non sp√©cifi√©e' else doc_name
            relevant_docs.append(formatted)
    
    # Ajouter les sources ou fallback
    if relevant_docs:
        for doc in relevant_docs[:5]:  # Max 5 sources
            sources_section += f"‚Ä¢ {doc}\n"
    else:
        # Si aucun document sp√©cifique identifi√©, utiliser tous
        for doc in documents[:3]:  # Max 3 sources
            metadata = doc.metadata if hasattr(doc, 'metadata') else {}
            doc_name = metadata.get('pdf_name', 'Document ANSD')
            page_num = metadata.get('page_num', 'Non sp√©cifi√©e')
            
            if '/' in doc_name:
                doc_name = doc_name.split('/')[-1]
            
            formatted = f"{doc_name}, page {page_num}" if page_num != 'Non sp√©cifi√©e' else doc_name
            sources_section += f"‚Ä¢ {formatted}\n"
    
    return sources_section

def create_external_ansd_sources(response_content):
    """Cr√©e la section sources pour les connaissances ANSD externes."""
    
    sources_section = "\n\nüìö **Sources utilis√©es :**\n"
    
    response_lower = response_content.lower()
    
    # D√©tecter les sources sp√©cifiques mentionn√©es dans la r√©ponse
    detected_sources = []
    
    # Enqu√™tes sp√©cifiques
    if 'ehcvm' in response_lower or 'conditions de vie' in response_lower:
        detected_sources.append("‚Ä¢ ANSD - Enqu√™te Harmonis√©e sur les Conditions de Vie des M√©nages (EHCVM), 2018-2019")
    
    if 'esps' in response_lower or 'pauvret√©' in response_lower:
        detected_sources.append("‚Ä¢ ANSD - Enqu√™te de Suivi de la Pauvret√© au S√©n√©gal (ESPS), 2018-2019")
    
    if 'eds' in response_lower or 'd√©mographique et sant√©' in response_lower:
        detected_sources.append("‚Ä¢ ANSD - Enqu√™te D√©mographique et de Sant√© (EDS), 2023")
    
    if 'rgph' in response_lower or 'recensement' in response_lower:
        detected_sources.append("‚Ä¢ ANSD - Recensement G√©n√©ral de la Population et de l'Habitat (RGPH), 2023")
    
    if 'enes' in response_lower or 'emploi' in response_lower:
        detected_sources.append("‚Ä¢ ANSD - Enqu√™te Nationale sur l'Emploi au S√©n√©gal (ENES), 2021")
    
    # Toujours ajouter le site officiel
    detected_sources.append("‚Ä¢ Site officiel ANSD (www.ansd.sn)")
    
    # Ajouter note explicative
    sources_section += "‚Ä¢ **Note :** Informations issues des connaissances des publications ANSD officielles\n"
    
    # Ajouter les sources d√©tect√©es
    for source in detected_sources:
        sources_section += f"{source}\n"
    
    return sources_section

# =============================================================================
# EXEMPLE DE FLUX COMPLET
# =============================================================================

"""
EXEMPLE DE FONCTIONNEMENT :

Question: "Quel est le taux de pauvret√© au S√©n√©gal ?"

√âTAPE 1 - Documents index√©s :
- Cherche dans les documents RGPH, EDS, etc.
- Trouve des infos sur mortalit√©, population, mais pas pauvret√©
- √âvaluation : √âCHEC (pas d'info sur pauvret√©)

√âTAPE 2 - Connaissances ANSD :
- Utilise les connaissances des enqu√™tes EHCVM/ESPS
- Trouve : "36,5% selon EHCVM 2018-2019"
- √âvaluation : SUCC√àS

R√âSULTAT :
üìö **Sources utilis√©es :**
‚Ä¢ Note : Informations issues des connaissances des publications ANSD officielles
‚Ä¢ ANSD - Enqu√™te Harmonis√©e sur les Conditions de Vie des M√©nages (EHCVM), 2018-2019
‚Ä¢ Site officiel ANSD (www.ansd.sn)
"""
# =============================================================================
# FONCTION D'ANALYSE INTELLIGENTE DES SOURCES
# =============================================================================

def analyze_response_sources(response_content, documents, user_question):
    """Analyse intelligente pour d√©terminer quelles sources ont √©t√© r√©ellement utilis√©es."""
    
    import re
    
    analysis = {
        'relevant_documents': [],
        'llm_sources': [],
        'recommendation': 'use_llm',  # Par d√©faut
        'confidence': 0
    }
    
    # 1. ANALYSER LES SOURCES MENTIONN√âES DANS LA R√âPONSE
    response_lower = response_content.lower()
    
    # Extraire les sources LLM mentionn√©es dans la r√©ponse
    llm_source_patterns = [
        r'ANSD\s*-\s*([^,\n]+)',
        r'Enqu√™te\s+[^,\n]+\s*\([^)]+\)',
        r'Site officiel ANSD',
        r'www\.ansd\.sn',
        r'publications?\s+officielles?\s+ANSD',
        r'selon les publications ANSD',
        r'EHCVM\s*[,\s]*20\d{2}',
        r'ESPS\s*[,\s]*20\d{2}',
        r'EDS\s*[,\s]*20\d{2}',
    ]
    
    for pattern in llm_source_patterns:
        matches = re.findall(pattern, response_content, re.IGNORECASE)
        for match in matches:
            if isinstance(match, str) and len(match.strip()) > 3:
                analysis['llm_sources'].append(match.strip())
    
    # 2. ANALYSER LA PERTINENCE DES DOCUMENTS RAG
    question_keywords = extract_question_keywords(user_question)
    
    for doc in documents:
        relevance_score = calculate_document_relevance(doc, question_keywords, response_content)
        
        if relevance_score >  0.15:  # Seuil de pertinence
            metadata = doc.metadata if hasattr(doc, 'metadata') else {}
            doc_name = extract_document_name_clean(metadata)
            page_info = extract_page_info_clean(metadata)
            
            analysis['relevant_documents'].append({
                'name': doc_name,
                'page': page_info,
                'relevance': relevance_score,
                'formatted': f"{doc_name}, {page_info}" if page_info != "page non sp√©cifi√©e" else doc_name
            })
    
    # 3. STRAT√âGIE DE D√âCISION INTELLIGENTE
    has_relevant_docs = len(analysis['relevant_documents']) > 0
    has_llm_sources = len(analysis['llm_sources']) > 0
    
    # Analyser si la r√©ponse contient des informations des documents
    contains_doc_info = analyze_content_origin(response_content, documents)
    
    if has_relevant_docs and contains_doc_info:
        analysis['recommendation'] = 'use_documents'
        analysis['confidence'] = 0.8
    elif has_llm_sources and not contains_doc_info:
        analysis['recommendation'] = 'use_llm'
        analysis['confidence'] = 0.9
    elif has_llm_sources and has_relevant_docs:
        # Cas mixte - analyser la dominance
        if len(analysis['llm_sources']) > len(analysis['relevant_documents']):
            analysis['recommendation'] = 'use_llm'
            analysis['confidence'] = 0.6
        else:
            analysis['recommendation'] = 'use_mixed'
            analysis['confidence'] = 0.7
    else:
        analysis['recommendation'] = 'use_llm'  # Fallback
        analysis['confidence'] = 0.5
    
    return analysis

# =============================================================================
# FONCTIONS UTILITAIRES D'ANALYSE
# =============================================================================

def extract_question_keywords(question):
    """Extrait les mots-cl√©s pertinents de la question."""
    
    # Mots-cl√©s importants pour diff√©rents domaines
    domain_keywords = {
        'pauvret√©': ['pauvret√©', 'pauvre', 'indigence', 'conditions', 'vie', 'revenus', 'esps', 'ehcvm'],
        'population': ['population', 'habitants', 'd√©mographie', 'recensement', 'rgph'],
        '√©ducation': ['alphab√©tisation', '√©ducation', '√©cole', 'scolarisation', 'enseignement'],
        'sant√©': ['sant√©', 'mortalit√©', 'morbidit√©', 'maternelle', 'infantile', 'eds'],
        '√©conomie': ['√©conomie', 'pib', 'croissance', 'emploi', 'ch√¥mage', 'enes'],
    }
    
    question_lower = question.lower()
    found_keywords = []
    
    for domain, keywords in domain_keywords.items():
        for keyword in keywords:
            if keyword in question_lower:
                found_keywords.append((keyword, domain))
    
    return found_keywords

def calculate_document_relevance(doc, question_keywords, response_content):
    """Calcule la pertinence d'un document par rapport √† la question et √† la r√©ponse."""
    
    doc_content = doc.page_content.lower()
    response_lower = response_content.lower()
    
    relevance_score = 0
    
    # Score bas√© sur les mots-cl√©s de la question
    for keyword, domain in question_keywords:
        if keyword in doc_content:
            relevance_score += 0.2
    
    # Score bas√© sur la pr√©sence d'informations du document dans la r√©ponse
    doc_words = set(doc_content.split())
    response_words = set(response_lower.split())
    
    # Mots significatifs (plus de 4 caract√®res, pas trop communs)
    significant_words = {word for word in doc_words if len(word) > 4 and word not in 
                        ['selon', 'dans', 'avec', 'pour', 'sont', 'cette', 'leurs', 'plus']}
    
    common_significant = significant_words.intersection(response_words)
    
    if len(significant_words) > 0:
        overlap_ratio = len(common_significant) / len(significant_words)
        relevance_score += overlap_ratio * 0.5
    
    # Bonus pour les donn√©es num√©riques communes
    import re
    doc_numbers = set(re.findall(r'\d+[.,]?\d*', doc_content))
    response_numbers = set(re.findall(r'\d+[.,]?\d*', response_lower))
    
    if doc_numbers and response_numbers:
        number_overlap = len(doc_numbers.intersection(response_numbers))
        if number_overlap > 0:
            relevance_score += 0.3
    
    return min(relevance_score, 1.0)  # Cap √† 1.0

def analyze_content_origin(response_content, documents):
    """Analyse si la r√©ponse provient principalement des documents ou des connaissances LLM."""
    
    # Indicateurs que la r√©ponse vient des documents
    doc_indicators = [
        'selon les documents fournis',
        'd\'apr√®s le document',
        'page ',
        'chapitre ',
        'rapport provisoire',
        'rgph5',
        'juillet2024'
    ]
    
    # Indicateurs que la r√©ponse vient des connaissances LLM
    llm_indicators = [
        'selon les donn√©es les plus r√©centes',
        'ansd estime',
        'site officiel ansd',
        'publications ansd',
        'ehcvm 2018',
        'esps 2018',
        'www.ansd.sn'
    ]
    
    response_lower = response_content.lower()
    
    doc_score = sum(1 for indicator in doc_indicators if indicator in response_lower)
    llm_score = sum(1 for indicator in llm_indicators if indicator in response_lower)
    
    return doc_score > llm_score

# =============================================================================
# FONCTIONS DE NETTOYAGE DES M√âTADONN√âES
# =============================================================================

def extract_document_name_clean(metadata):
    """Extrait le nom du document de mani√®re propre."""
    
    if not metadata:
        return "Document ANSD"
    
    name_fields = ['pdf_name', 'source', 'filename', 'title']
    
    for field in name_fields:
        if field in metadata and metadata[field]:
            doc_name = str(metadata[field])
            
            # Nettoyer le nom
            if '/' in doc_name:
                doc_name = doc_name.split('/')[-1]
            if '\\' in doc_name:
                doc_name = doc_name.split('\\')[-1]
            
            return doc_name
    
    return "Document ANSD"

def extract_page_info_clean(metadata):
    """Extrait l'information de page de mani√®re propre."""
    
    if not metadata:
        return "page non sp√©cifi√©e"
    
    page_fields = ['page_num', 'page', 'page_number']
    
    for field in page_fields:
        if field in metadata and metadata[field] is not None:
            try:
                page_num = int(float(metadata[field]))
                return f"page {page_num}"
            except (ValueError, TypeError):
                return f"page {metadata[field]}"
    
    return "page non sp√©cifi√©e"

# =============================================================================
# APPLICATION DE LA STRAT√âGIE INTELLIGENTE
# =============================================================================

def apply_intelligent_source_strategy(response_content, source_analysis):
    """Applique la strat√©gie intelligente de sources bas√©e sur l'analyse."""
    
    import re
    
    # Supprimer toutes les sections sources existantes
    cleaned_content = remove_all_existing_sources(response_content)
    
    if source_analysis['recommendation'] == 'use_documents':
        # Utiliser les sources de documents pertinents
        sources_section = "\n\nüìö **Sources utilis√©es :**\n"
        for doc in source_analysis['relevant_documents']:
            sources_section += f"‚Ä¢ {doc['formatted']}\n"
        
    elif source_analysis['recommendation'] == 'use_llm':
        # Utiliser les sources LLM d√©tect√©es
        sources_section = "\n\nüìö **Sources utilis√©es :**\n"
        
        # Sources LLM standardis√©es
        if 'ehcvm' in response_content.lower() or 'pauvret√©' in response_content.lower():
            sources_section += "‚Ä¢ ANSD - Enqu√™te Harmonis√©e sur les Conditions de Vie des M√©nages (EHCVM), 2018-2019\n"
        if 'site officiel' in response_content.lower() or 'www.ansd.sn' in response_content.lower():
            sources_section += "‚Ä¢ Site officiel ANSD (www.ansd.sn)\n"
        
        # Ajouter d'autres sources LLM d√©tect√©es
        for source in source_analysis['llm_sources']:
            if source not in sources_section:
                sources_section += f"‚Ä¢ ANSD - {source}\n"
        
        # Si aucune source sp√©cifique, utiliser g√©n√©rique
        if sources_section == "\n\nüìö **Sources utilis√©es :**\n":
            sources_section += "‚Ä¢ Connaissances officielles ANSD\n‚Ä¢ Site officiel ANSD (www.ansd.sn)\n"
    
    elif source_analysis['recommendation'] == 'use_mixed':
        # Combiner sources documents + LLM
        sources_section = "\n\nüìö **Sources utilis√©es :**\n"
        sources_section += "\n**üìÑ Documents analys√©s :**\n"
        for doc in source_analysis['relevant_documents']:
            sources_section += f"‚Ä¢ {doc['formatted']}\n"
        
        sources_section += "\n**üåê Publications ANSD officielles :**\n"
        for source in source_analysis['llm_sources']:
            sources_section += f"‚Ä¢ ANSD - {source}\n"
        sources_section += "‚Ä¢ Site officiel ANSD (www.ansd.sn)\n"
    
    else:
        # Fallback
        sources_section = "\n\nüìö **Sources utilis√©es :**\n‚Ä¢ Connaissances g√©n√©rales ANSD\n"
    
    return cleaned_content + sources_section

def remove_all_existing_sources(content):
    """Supprime toutes les sections sources existantes."""
    
    import re
    
    patterns = [
        r'üìö\s*\*?\*?Sources?\s+utilis√©es?\s*:.*?(?=\n\n|\Z)',
        r'\*\*?üìö.*?Sources?\s+utilis√©es?\s*:?\*?\*?.*?(?=\n\n|\Z)',
        r'Sources?\s+utilis√©es?\s*:.*?(?=\n\n|\Z)',
    ]
    
    cleaned = content
    for pattern in patterns:
        cleaned = re.sub(pattern, '', cleaned, flags=re.DOTALL | re.IGNORECASE)
    
    # Nettoyer les espaces multiples
    cleaned = re.sub(r'\n\s*\n\s*\n', '\n\n', cleaned)
    return cleaned.strip()

# =============================================================================
# FONCTION D'EXTRACTION DES SOURCES PRIORITAIRES
# =============================================================================

def extract_priority_sources(documents):
    """Extrait les sources prioritaires (documents avec m√©tadonn√©es compl√®tes)."""
    
    priority_sources = []
    
    for doc in documents:
        metadata = doc.metadata if hasattr(doc, 'metadata') else {}
        
        # V√©rifier si on a les m√©tadonn√©es essentielles
        has_doc_name = any(key in metadata and metadata[key] for key in ['pdf_name', 'source', 'filename'])
        has_page_info = any(key in metadata and metadata[key] is not None for key in ['page_num', 'page', 'page_number'])
        
        if has_doc_name:  # Au minimum le nom du document
            # Extraire le nom du document
            doc_name = "Document ANSD"
            if 'pdf_name' in metadata and metadata['pdf_name']:
                doc_name = str(metadata['pdf_name'])
            elif 'source' in metadata and metadata['source']:
                doc_name = str(metadata['source'])
            elif 'filename' in metadata and metadata['filename']:
                doc_name = str(metadata['filename'])
            
            # Nettoyer le nom
            if '/' in doc_name:
                doc_name = doc_name.split('/')[-1]
            if '\\' in doc_name:
                doc_name = doc_name.split('\\')[-1]
            
            # Extraire la page si disponible
            page_info = None
            if has_page_info:
                if 'page_num' in metadata and metadata['page_num'] is not None:
                    try:
                        page_num = int(float(metadata['page_num']))
                        page_info = f"page {page_num}"
                    except (ValueError, TypeError):
                        page_info = f"page {metadata['page_num']}"
                elif 'page' in metadata and metadata['page'] is not None:
                    try:
                        page_num = int(float(metadata['page']))
                        page_info = f"page {page_num}"
                    except (ValueError, TypeError):
                        page_info = f"page {metadata['page']}"
            
            # Cr√©er la source format√©e
            if page_info:
                source_formatted = f"{doc_name}, {page_info}"
            else:
                source_formatted = doc_name
            
            priority_sources.append(source_formatted)
    
    # Supprimer les doublons tout en gardant l'ordre
    seen = set()
    unique_sources = []
    for source in priority_sources:
        if source not in seen:
            seen.add(source)
            unique_sources.append(source)
    
    return unique_sources

# =============================================================================
# FONCTION POUR UTILISER LES SOURCES DE DOCUMENTS (PRIORIT√â 1)
# =============================================================================

def use_document_sources(response_content, priority_sources):
    """Utilise les sources de documents en supprimant les sources LLM existantes."""
    
    import re
    
    # Supprimer toutes les sections sources existantes de la r√©ponse LLM
    # Pattern pour capturer les sections sources multiples
    patterns_to_remove = [
        r'üìö\s*\*?\*?Sources?\s+utilis√©es?\s*:.*?(?=\n\n|\Z)',
        r'\*\*?üìö.*?Sources?\s+utilis√©es?\s*:?\*?\*?.*?(?=\n\n|\Z)',
        r'Sources?\s+utilis√©es?\s*:.*?(?=\n\n|\Z)',
    ]
    
    cleaned_content = response_content
    for pattern in patterns_to_remove:
        cleaned_content = re.sub(pattern, '', cleaned_content, flags=re.DOTALL | re.IGNORECASE)
    
    # Nettoyer les espaces multiples et lignes vides
    cleaned_content = re.sub(r'\n\s*\n\s*\n', '\n\n', cleaned_content)
    cleaned_content = cleaned_content.strip()
    
    # Ajouter la section sources de documents
    sources_section = "\n\nüìö **Sources utilis√©es :**\n"
    for source in priority_sources:
        sources_section += f"‚Ä¢ {source}\n"
    
    final_content = cleaned_content + sources_section
    
    return final_content

# =============================================================================
# FONCTION POUR PR√âSERVER LES SOURCES LLM (PRIORIT√â 2)
# =============================================================================

def preserve_llm_sources(response_content):
    """Pr√©serve les sources g√©n√©r√©es par le LLM quand pas de sources de documents."""
    
    import re
    
    # V√©rifier si le LLM a g√©n√©r√© des sources
    has_llm_sources = bool(re.search(r'üìö|Sources?\s+utilis√©es?', response_content, re.IGNORECASE))
    
    if has_llm_sources:
        print("‚úÖ Sources LLM d√©tect√©es - conservation")
        
        # Nettoyer le format des sources LLM pour uniformiser
        # Remplacer les * par des ‚Ä¢ pour coh√©rence
        formatted_content = re.sub(r'(\n\s*)\*(\s+)', r'\1‚Ä¢\2', response_content)
        
        # S'assurer que la section sources a le bon format
        formatted_content = re.sub(
            r'üìö\s*\*?\*?Sources?\s+utilis√©es?\s*:?',
            'üìö **Sources utilis√©es :**',
            formatted_content,
            flags=re.IGNORECASE
        )
        
        return formatted_content
    
    else:
        print("‚ö†Ô∏è Aucune source LLM d√©tect√©e - ajout note explicative")
        
        # Ajouter une note explicative
        note_section = "\n\nüìö **Sources utilis√©es :**\n‚Ä¢ Connaissances g√©n√©rales ANSD (aucun document sp√©cifique fourni)\n"
        return response_content + note_section

# =============================================================================
# FONCTION DE DIAGNOSTIC DES SOURCES
# =============================================================================

def diagnose_sources(documents, response_content):
    """Diagnostique les sources disponibles pour d√©bogage."""
    
    print("\nüîç DIAGNOSTIC DES SOURCES:")
    print("="*50)
    
    # Analyser les documents
    print(f"üìÑ Documents fournis: {len(documents)}")
    for i, doc in enumerate(documents, 1):
        metadata = doc.metadata if hasattr(doc, 'metadata') else {}
        print(f"   Document {i}:")
        print(f"      pdf_name: {metadata.get('pdf_name', 'Non d√©fini')}")
        print(f"      page_num: {metadata.get('page_num', 'Non d√©fini')}")
        print(f"      source: {metadata.get('source', 'Non d√©fini')}")
    
    # Analyser les sources prioritaires
    priority_sources = extract_priority_sources(documents)
    print(f"\nüîù Sources prioritaires extraites: {len(priority_sources)}")
    for i, source in enumerate(priority_sources, 1):
        print(f"   {i}. {source}")
    
    # Analyser les sources dans la r√©ponse LLM
    import re
    llm_sources = re.findall(r'üìö.*?Sources.*?:(.*?)(?=\n\n|\Z)', response_content, re.DOTALL | re.IGNORECASE)
    print(f"\nü§ñ Sources LLM d√©tect√©es: {len(llm_sources)}")
    for i, sources_block in enumerate(llm_sources, 1):
        print(f"   Bloc {i}: {sources_block.strip()[:100]}...")
    
    print("="*50)

# =============================================================================
# FONCTION GENERATE AVEC DIAGNOSTIC (VERSION DEBUG)
# =============================================================================

async def generate_with_debug(state: GraphState, *, config: RagConfiguration):
    """Version avec diagnostic pour d√©boguer les sources."""
    
    print("ü§ñ ---GENERATE AVEC DEBUG SOURCES---")
    
    messages = state.messages
    documents = state.documents
    
    prompt = ChatPromptTemplate.from_messages([
        ("system", IMPROVED_ANSD_SYSTEM_PROMPT),
        ("placeholder", "{messages}")
    ])
    
    configuration = RagConfiguration.from_runnable_config(config)
    model = load_chat_model(configuration.model)
    context = format_docs_with_rich_metadata(documents)
    
    try:
        rag_chain = prompt | model
        response = await rag_chain.ainvoke({
            "context": context,
            "messages": messages
        })
        
        response_content = response.content
        
        # DIAGNOSTIC COMPLET
        diagnose_sources(documents, response_content)
        
        # Appliquer la logique de priorit√©
        priority_sources = extract_priority_sources(documents)
        
        if priority_sources:
            print("üîù STRAT√âGIE: Utilisation des sources de documents")
            final_response = use_document_sources(response_content, priority_sources)
        else:
            print("ü§ñ STRAT√âGIE: Conservation des sources LLM")
            final_response = preserve_llm_sources(response_content)
        
        from langchain_core.messages import AIMessage
        enhanced_response = AIMessage(content=final_response)
        
        return {"messages": [enhanced_response], "documents": documents}
        
    except Exception as e:
        print(f"‚ùå Erreur: {e}")
        from langchain_core.messages import AIMessage
        fallback = AIMessage(content="‚ùå Erreur technique ANSD.")
        return {"messages": [fallback], "documents": documents}


# =============================================================================
# CONFIGURATION DU WORKFLOW (NE PAS MODIFIER)
# =============================================================================

workflow = StateGraph(GraphState, input=InputState, config_schema=RagConfiguration)

# Define the nodes
workflow.add_node("retrieve", retrieve)
workflow.add_node("generate", generate)

# Build graph
workflow.add_edge(START, "retrieve")
workflow.add_edge("retrieve", "generate")
workflow.add_edge("generate", END)

# Compile
graph = workflow.compile()
graph.name = "ImprovedSimpleRag"